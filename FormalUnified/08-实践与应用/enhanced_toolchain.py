#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå·¥å…·é“¾é›†æˆè„šæœ¬
æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½ç›‘æ§å’Œåä½œæœºåˆ¶
"""

import sys
import os
import logging
import json
import time
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_toolchain.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

@dataclass
class ToolResult:
    """å·¥å…·æ‰§è¡Œç»“æœ"""
    success: bool
    data: Any
    error: Optional[str] = None
    execution_time: float = 0.0
    metadata: Optional[Dict[str, Any]] = None

class EnhancedToolchain:
    """å¢å¼ºç‰ˆå·¥å…·é“¾é›†æˆå™¨"""
    
    def __init__(self):
        self.tools = {}
        self.workflow_history = []
        self.performance_metrics = {}
        self.error_log = []
        
        # åˆå§‹åŒ–å·¥å…·
        self._initialize_tools()
        
    def _initialize_tools(self):
        """åˆå§‹åŒ–æ‰€æœ‰å·¥å…·"""
        try:
            # AIå»ºæ¨¡å¼•æ“
            from AI_Modeling_Engine.prototype import AIModelingEngine, ModelType, PropertyType
            self.tools['ai_engine'] = AIModelingEngine()
            logger.info("âœ… AIå»ºæ¨¡å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            
            # æ¨¡å‹å¯è§†åŒ–å·¥å…·
            from FormalTools.model_visualizer import ModelVisualizer
            self.tools['visualizer'] = ModelVisualizer()
            logger.info("âœ… æ¨¡å‹å¯è§†åŒ–å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
            
            # å½¢å¼éªŒè¯å·¥å…·
            from VerificationTools.formal_checker import FormalVerificationEngine, PropertySpec
            self.tools['verifier'] = FormalVerificationEngine()
            logger.info("âœ… å½¢å¼éªŒè¯å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
            
        except ImportError as e:
            logger.error(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def execute_workflow(self, workflow_config: Dict[str, Any]) -> Dict[str, ToolResult]:
        """æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹"""
        start_time = time.time()
        workflow_id = f"workflow_{int(start_time)}"
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµç¨‹: {workflow_id}")
        logger.info(f"é…ç½®: {json.dumps(workflow_config, indent=2, ensure_ascii=False)}")
        
        results = {}
        
        try:
            # é˜¶æ®µ1: AIå»ºæ¨¡
            if 'modeling' in workflow_config:
                results['modeling'] = self._execute_modeling(workflow_config['modeling'])
            
            # é˜¶æ®µ2: æ¨¡å‹å¯è§†åŒ–
            if 'visualization' in workflow_config and results.get('modeling', {}).success:
                results['visualization'] = self._execute_visualization(
                    results['modeling'].data, 
                    workflow_config['visualization']
                )
            
            # é˜¶æ®µ3: å½¢å¼éªŒè¯
            if 'verification' in workflow_config and results.get('modeling', {}).success:
                results['verification'] = self._execute_verification(
                    results['modeling'].data,
                    workflow_config['verification']
                )
            
            # é˜¶æ®µ4: ä»£ç ç”Ÿæˆ
            if 'code_generation' in workflow_config and results.get('modeling', {}).success:
                results['code_generation'] = self._execute_code_generation(
                    results['modeling'].data,
                    workflow_config['code_generation']
                )
            
            # è®°å½•å·¥ä½œæµç¨‹å†å²
            workflow_duration = time.time() - start_time
            self.workflow_history.append({
                'id': workflow_id,
                'config': workflow_config,
                'results': results,
                'duration': workflow_duration,
                'timestamp': start_time
            })
            
            logger.info(f"âœ… å·¥ä½œæµç¨‹æ‰§è¡Œå®Œæˆ: {workflow_id} (è€—æ—¶: {workflow_duration:.2f}s)")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            self.error_log.append({
                'workflow_id': workflow_id,
                'error': str(e),
                'traceback': traceback.format_exc(),
                'timestamp': time.time()
            })
        
        return results
    
    def _execute_modeling(self, config: Dict[str, Any]) -> ToolResult:
        """æ‰§è¡ŒAIå»ºæ¨¡"""
        start_time = time.time()
        
        try:
            requirements = config.get('requirements', '')
            model_type = getattr(ModelType, config.get('model_type', 'STATE_MACHINE'))
            
            result = self.tools['ai_engine'].process_requirements(requirements, model_type)
            
            execution_time = time.time() - start_time
            return ToolResult(
                success=True,
                data=result,
                execution_time=execution_time,
                metadata={'tool': 'ai_engine', 'config': config}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return ToolResult(
                success=False,
                data=None,
                error=str(e),
                execution_time=execution_time,
                metadata={'tool': 'ai_engine', 'config': config}
            )
    
    def _execute_visualization(self, model_data: Dict[str, Any], config: Dict[str, Any]) -> ToolResult:
        """æ‰§è¡Œæ¨¡å‹å¯è§†åŒ–"""
        start_time = time.time()
        
        try:
            output_file = config.get('output_file', f"visualization_{model_data.get('model_id', 'unknown')}.png")
            
            self.tools['visualizer'].visualize_model(model_data, output_file)
            
            execution_time = time.time() - start_time
            return ToolResult(
                success=True,
                data={'output_file': output_file},
                execution_time=execution_time,
                metadata={'tool': 'visualizer', 'config': config}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return ToolResult(
                success=False,
                data=None,
                error=str(e),
                execution_time=execution_time,
                metadata={'tool': 'visualizer', 'config': config}
            )
    
    def _execute_verification(self, model_data: Dict[str, Any], config: Dict[str, Any]) -> ToolResult:
        """æ‰§è¡Œå½¢å¼éªŒè¯"""
        start_time = time.time()
        
        try:
            properties = config.get('properties', [])
            verification_result = self.tools['verifier'].verify_model(model_data, properties)
            
            execution_time = time.time() - start_time
            return ToolResult(
                success=True,
                data=verification_result,
                execution_time=execution_time,
                metadata={'tool': 'verifier', 'config': config}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return ToolResult(
                success=False,
                data=None,
                error=str(e),
                execution_time=execution_time,
                metadata={'tool': 'verifier', 'config': config}
            )
    
    def _execute_code_generation(self, model_data: Dict[str, Any], config: Dict[str, Any]) -> ToolResult:
        """æ‰§è¡Œä»£ç ç”Ÿæˆ"""
        start_time = time.time()
        
        try:
            target_language = config.get('target_language', 'rust')
            output_dir = config.get('output_dir', './generated_code')
            
            # è¿™é‡Œéœ€è¦å®ç°ä»£ç ç”Ÿæˆé€»è¾‘
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
            generated_files = [f"{output_dir}/main.{target_language}"]
            
            execution_time = time.time() - start_time
            return ToolResult(
                success=True,
                data={'generated_files': generated_files, 'target_language': target_language},
                execution_time=execution_time,
                metadata={'tool': 'code_generator', 'config': config}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return ToolResult(
                success=False,
                data=None,
                error=str(e),
                execution_time=execution_time,
                metadata={'tool': 'code_generator', 'config': config}
            )
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        if not self.workflow_history:
            return {"message": "æš‚æ— å·¥ä½œæµç¨‹å†å²"}
        
        total_workflows = len(self.workflow_history)
        successful_workflows = len([w for w in self.workflow_history if all(r.success for r in w['results'].values())])
        
        avg_duration = sum(w['duration'] for w in self.workflow_history) / total_workflows
        
        tool_performance = {}
        for workflow in self.workflow_history:
            for tool_name, result in workflow['results'].items():
                if tool_name not in tool_performance:
                    tool_performance[tool_name] = {'total_time': 0, 'count': 0, 'errors': 0}
                
                tool_performance[tool_name]['total_time'] += result.execution_time
                tool_performance[tool_name]['count'] += 1
                if not result.success:
                    tool_performance[tool_name]['errors'] += 1
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        for tool_name, stats in tool_performance.items():
            if stats['count'] > 0:
                stats['avg_time'] = stats['total_time'] / stats['count']
                stats['success_rate'] = (stats['count'] - stats['errors']) / stats['count']
        
        return {
            'total_workflows': total_workflows,
            'successful_workflows': successful_workflows,
            'success_rate': successful_workflows / total_workflows,
            'average_duration': avg_duration,
            'tool_performance': tool_performance,
            'error_summary': self.error_log
        }
    
    def export_workflow_report(self, output_file: str = "workflow_report.json"):
        """å¯¼å‡ºå·¥ä½œæµç¨‹æŠ¥å‘Š"""
        report = {
            'timestamp': time.time(),
            'performance': self.get_performance_report(),
            'workflow_history': self.workflow_history,
            'error_log': self.error_log
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š å·¥ä½œæµç¨‹æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_file}")

def demo_enhanced_toolchain():
    """æ¼”ç¤ºå¢å¼ºç‰ˆå·¥å…·é“¾"""
    logger.info("ğŸ¯ å¼€å§‹æ¼”ç¤ºå¢å¼ºç‰ˆå·¥å…·é“¾")
    
    toolchain = EnhancedToolchain()
    
    # é…ç½®ç¤ºä¾‹å·¥ä½œæµç¨‹
    workflow_config = {
        'modeling': {
            'requirements': 'åˆ›å»ºä¸€ä¸ªå¾®æœåŠ¡æ¶æ„çš„ç”µå•†ç³»ç»Ÿï¼ŒåŒ…å«ç”¨æˆ·ç®¡ç†ã€å•†å“ç®¡ç†ã€è®¢å•ç®¡ç†ä¸‰ä¸ªæœåŠ¡',
            'model_type': 'MICROSERVICE'
        },
        'visualization': {
            'output_file': 'ecommerce_microservice.png'
        },
        'verification': {
            'properties': ['æœåŠ¡é—´é€šä¿¡æ­£ç¡®æ€§', 'æ•°æ®ä¸€è‡´æ€§', 'æ•…éšœéš”ç¦»']
        },
        'code_generation': {
            'target_language': 'rust',
            'output_dir': './generated_ecommerce'
        }
    }
    
    # æ‰§è¡Œå·¥ä½œæµç¨‹
    results = toolchain.execute_workflow(workflow_config)
    
    # æ˜¾ç¤ºç»“æœ
    logger.info("\nğŸ“‹ å·¥ä½œæµç¨‹æ‰§è¡Œç»“æœ:")
    for stage, result in results.items():
        status = "âœ…" if result.success else "âŒ"
        logger.info(f"{status} {stage}: {result.success}")
        if result.error:
            logger.error(f"   é”™è¯¯: {result.error}")
        if result.data:
            logger.info(f"   æ•°æ®: {result.data}")
    
    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    performance_report = toolchain.get_performance_report()
    logger.info(f"\nğŸ“Š æ€§èƒ½æŠ¥å‘Š:")
    logger.info(f"æ€»å·¥ä½œæµç¨‹æ•°: {performance_report['total_workflows']}")
    logger.info(f"æˆåŠŸç‡: {performance_report['success_rate']:.2%}")
    logger.info(f"å¹³å‡è€—æ—¶: {performance_report['average_duration']:.2f}s")
    
    # å¯¼å‡ºæŠ¥å‘Š
    toolchain.export_workflow_report()
    
    return toolchain

if __name__ == "__main__":
    try:
        demo_enhanced_toolchain()
    except Exception as e:
        logger.error(f"æ¼”ç¤ºå¤±è´¥: {e}")
        traceback.print_exc() 