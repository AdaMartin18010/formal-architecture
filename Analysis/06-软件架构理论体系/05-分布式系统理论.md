# 06-软件架构理论体系-分布式系统理论

[返回主题树](../00-主题树与内容索引.md) | [主计划文档](../00-形式化架构理论统一计划.md)

## 目录

- [06-软件架构理论体系-分布式系统理论](#06-软件架构理论体系-分布式系统理论)
  - [目录](#目录)
  - [1. 分布式系统概述](#1-分布式系统概述)
    - [1.1 基本概念](#11-基本概念)
    - [1.2 系统特性](#12-系统特性)
  - [2. 一致性理论](#2-一致性理论)
    - [2.1 强一致性](#21-强一致性)
    - [2.2 最终一致性](#22-最终一致性)
  - [3. 容错机制](#3-容错机制)
    - [3.1 故障检测](#31-故障检测)
    - [3.2 故障恢复](#32-故障恢复)
  - [4. 分布式算法](#4-分布式算法)
    - [4.1 共识算法](#41-共识算法)
  - [5. 分布式存储](#5-分布式存储)
    - [5.1 数据分片](#51-数据分片)
    - [5.2 数据复制](#52-数据复制)
  - [6. 总结](#6-总结)

## 1. 分布式系统概述

### 1.1 基本概念

**分布式系统**是由多个独立节点组成的系统，节点通过网络通信协作完成共同目标。

**核心概念**：

- 节点：系统中的独立计算单元
- 网络：节点间的通信基础设施
- 一致性：数据在多个节点间的同步
- 容错：系统在部分节点故障时的可用性

### 1.2 系统特性

**CAP定理**：

- 一致性(Consistency)：所有节点看到相同的数据
- 可用性(Availability)：系统始终响应请求
- 分区容错性(Partition tolerance)：网络分区时系统仍能工作

## 2. 一致性理论

### 2.1 强一致性

**强一致性实现**：

```rust
pub struct StrongConsistency {
    coordinator: Coordinator,
    replicas: HashMap<NodeId, Replica>,
    quorum_size: usize,
}

impl StrongConsistency {
    pub fn new(quorum_size: usize) -> Self {
        Self {
            coordinator: Coordinator::new(),
            replicas: HashMap::new(),
            quorum_size,
        }
    }
    
    pub fn write(&mut self, key: String, value: String) -> Result<(), ConsistencyError> {
        // 两阶段提交
        let transaction_id = self.coordinator.begin_transaction();
        
        // 阶段1：准备
        let prepare_responses = self.prepare_phase(transaction_id, &key, &value)?;
        
        if prepare_responses.len() >= self.quorum_size {
            // 阶段2：提交
            self.commit_phase(transaction_id, &key, &value)?;
            Ok(())
        } else {
            // 回滚
            self.abort_phase(transaction_id)?;
            Err(ConsistencyError::QuorumNotReached)
        }
    }
    
    pub fn read(&self, key: &str) -> Result<String, ConsistencyError> {
        let mut responses = Vec::new();
        
        for replica in self.replicas.values() {
            if let Ok(value) = replica.read(key) {
                responses.push(value);
            }
        }
        
        if responses.len() >= self.quorum_size {
            // 返回最新值
            let latest_value = self.get_latest_value(&responses);
            Ok(latest_value)
        } else {
            Err(ConsistencyError::QuorumNotReached)
        }
    }
    
    fn prepare_phase(&self, transaction_id: TransactionId, key: &str, value: &str) -> Result<Vec<PrepareResponse>, ConsistencyError> {
        let mut responses = Vec::new();
        
        for replica in self.replicas.values() {
            if let Ok(response) = replica.prepare(transaction_id, key, value) {
                responses.push(response);
            }
        }
        
        Ok(responses)
    }
    
    fn commit_phase(&mut self, transaction_id: TransactionId, key: &str, value: &str) -> Result<(), ConsistencyError> {
        for replica in self.replicas.values_mut() {
            replica.commit(transaction_id, key, value)?;
        }
        Ok(())
    }
    
    fn abort_phase(&mut self, transaction_id: TransactionId) -> Result<(), ConsistencyError> {
        for replica in self.replicas.values_mut() {
            replica.abort(transaction_id)?;
        }
        Ok(())
    }
    
    fn get_latest_value(&self, responses: &[String]) -> String {
        // 实现获取最新值的逻辑
        responses.last().cloned().unwrap_or_default()
    }
}

pub struct Coordinator {
    transaction_counter: AtomicU64,
}

impl Coordinator {
    pub fn new() -> Self {
        Self {
            transaction_counter: AtomicU64::new(0),
        }
    }
    
    pub fn begin_transaction(&self) -> TransactionId {
        let id = self.transaction_counter.fetch_add(1, Ordering::SeqCst);
        TransactionId::new(id)
    }
}

pub struct Replica {
    node_id: NodeId,
    data: HashMap<String, String>,
    pending_transactions: HashMap<TransactionId, PendingTransaction>,
}

impl Replica {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            data: HashMap::new(),
            pending_transactions: HashMap::new(),
        }
    }
    
    pub fn prepare(&mut self, transaction_id: TransactionId, key: &str, value: &str) -> Result<PrepareResponse, ConsistencyError> {
        let pending_tx = PendingTransaction {
            key: key.to_string(),
            value: value.to_string(),
            status: TransactionStatus::Prepared,
        };
        
        self.pending_transactions.insert(transaction_id, pending_tx);
        
        Ok(PrepareResponse {
            node_id: self.node_id,
            transaction_id,
            status: PrepareStatus::Prepared,
        })
    }
    
    pub fn commit(&mut self, transaction_id: TransactionId, key: &str, value: &str) -> Result<(), ConsistencyError> {
        if let Some(pending_tx) = self.pending_transactions.get(&transaction_id) {
            self.data.insert(key.to_string(), value.to_string());
            self.pending_transactions.remove(&transaction_id);
            Ok(())
        } else {
            Err(ConsistencyError::TransactionNotFound)
        }
    }
    
    pub fn abort(&mut self, transaction_id: TransactionId) -> Result<(), ConsistencyError> {
        self.pending_transactions.remove(&transaction_id);
        Ok(())
    }
    
    pub fn read(&self, key: &str) -> Result<String, ConsistencyError> {
        self.data.get(key)
            .cloned()
            .ok_or(ConsistencyError::KeyNotFound)
    }
}
```

### 2.2 最终一致性

**最终一致性实现**：

```rust
pub struct EventualConsistency {
    nodes: HashMap<NodeId, Node>,
    vector_clock: VectorClock,
    conflict_resolution: ConflictResolution,
}

impl EventualConsistency {
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
            vector_clock: VectorClock::new(),
            conflict_resolution: ConflictResolution::new(),
        }
    }
    
    pub fn write(&mut self, node_id: NodeId, key: String, value: String) -> Result<(), ConsistencyError> {
        let node = self.nodes.get_mut(&node_id)
            .ok_or(ConsistencyError::NodeNotFound)?;
        
        // 更新向量时钟
        let timestamp = self.vector_clock.increment(node_id);
        
        // 写入本地
        node.write(key.clone(), value.clone(), timestamp)?;
        
        // 异步传播到其他节点
        self.propagate_write(node_id, key, value, timestamp);
        
        Ok(())
    }
    
    pub fn read(&self, node_id: NodeId, key: &str) -> Result<String, ConsistencyError> {
        let node = self.nodes.get(&node_id)
            .ok_or(ConsistencyError::NodeNotFound)?;
        
        node.read(key)
    }
    
    fn propagate_write(&self, source_node: NodeId, key: String, value: String, timestamp: Timestamp) {
        // 异步传播写入操作到其他节点
        for (node_id, node) in &self.nodes {
            if *node_id != source_node {
                // 在实际系统中，这里会通过网络发送消息
                println!("传播写入到节点 {}: {} = {}", node_id, key, value);
            }
        }
    }
    
    pub fn merge_conflicts(&mut self, key: &str, versions: Vec<VersionedValue>) -> Result<String, ConsistencyError> {
        if versions.len() <= 1 {
            return Ok(versions.first().map(|v| v.value.clone()).unwrap_or_default());
        }
        
        // 检测冲突
        let conflicts = self.detect_conflicts(&versions);
        
        if conflicts.is_empty() {
            // 无冲突，返回最新版本
            let latest = versions.iter().max_by_key(|v| &v.timestamp).unwrap();
            Ok(latest.value.clone())
        } else {
            // 解决冲突
            self.conflict_resolution.resolve_conflicts(key, conflicts)
        }
    }
    
    fn detect_conflicts(&self, versions: &[VersionedValue]) -> Vec<Conflict> {
        let mut conflicts = Vec::new();
        
        for i in 0..versions.len() {
            for j in i + 1..versions.len() {
                let v1 = &versions[i];
                let v2 = &versions[j];
                
                if self.vector_clock.concurrent(&v1.timestamp, &v2.timestamp) {
                    conflicts.push(Conflict {
                        version1: v1.clone(),
                        version2: v2.clone(),
                    });
                }
            }
        }
        
        conflicts
    }
}

pub struct Node {
    node_id: NodeId,
    data: HashMap<String, VersionedValue>,
    vector_clock: VectorClock,
}

impl Node {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            data: HashMap::new(),
            vector_clock: VectorClock::new(),
        }
    }
    
    pub fn write(&mut self, key: String, value: String, timestamp: Timestamp) -> Result<(), ConsistencyError> {
        let versioned_value = VersionedValue {
            value,
            timestamp,
        };
        
        self.data.insert(key, versioned_value);
        Ok(())
    }
    
    pub fn read(&self, key: &str) -> Result<String, ConsistencyError> {
        self.data.get(key)
            .map(|v| v.value.clone())
            .ok_or(ConsistencyError::KeyNotFound)
    }
}

#[derive(Debug, Clone)]
pub struct VersionedValue {
    pub value: String,
    pub timestamp: Timestamp,
}

#[derive(Debug, Clone)]
pub struct Conflict {
    pub version1: VersionedValue,
    pub version2: VersionedValue,
}

pub struct ConflictResolution {
    strategies: HashMap<String, ConflictStrategy>,
}

impl ConflictResolution {
    pub fn new() -> Self {
        let mut strategies = HashMap::new();
        strategies.insert("last_write_wins".to_string(), ConflictStrategy::LastWriteWins);
        strategies.insert("merge_values".to_string(), ConflictStrategy::MergeValues);
        strategies.insert("user_resolution".to_string(), ConflictStrategy::UserResolution);
        
        Self { strategies }
    }
    
    pub fn resolve_conflicts(&self, key: &str, conflicts: Vec<Conflict>) -> Result<String, ConsistencyError> {
        let strategy = self.strategies.get("last_write_wins").unwrap();
        
        match strategy {
            ConflictStrategy::LastWriteWins => {
                self.last_write_wins(conflicts)
            },
            ConflictStrategy::MergeValues => {
                self.merge_values(conflicts)
            },
            ConflictStrategy::UserResolution => {
                self.user_resolution(conflicts)
            },
        }
    }
    
    fn last_write_wins(&self, conflicts: Vec<Conflict>) -> Result<String, ConsistencyError> {
        // 选择时间戳最大的版本
        let mut all_versions = Vec::new();
        for conflict in conflicts {
            all_versions.push(conflict.version1);
            all_versions.push(conflict.version2);
        }
        
        let latest = all_versions.iter().max_by_key(|v| &v.timestamp).unwrap();
        Ok(latest.value.clone())
    }
    
    fn merge_values(&self, conflicts: Vec<Conflict>) -> Result<String, ConsistencyError> {
        // 合并所有值
        let mut merged_value = String::new();
        
        for conflict in conflicts {
            merged_value.push_str(&conflict.version1.value);
            merged_value.push_str("|");
            merged_value.push_str(&conflict.version2.value);
        }
        
        Ok(merged_value)
    }
    
    fn user_resolution(&self, _conflicts: Vec<Conflict>) -> Result<String, ConsistencyError> {
        // 用户手动解决冲突
        Err(ConsistencyError::UserResolutionRequired)
    }
}

#[derive(Debug, Clone)]
pub enum ConflictStrategy {
    LastWriteWins,
    MergeValues,
    UserResolution,
}
```

## 3. 容错机制

### 3.1 故障检测

**故障检测器实现**：

```rust
pub struct FailureDetector {
    nodes: HashMap<NodeId, NodeStatus>,
    heartbeat_interval: Duration,
    timeout_duration: Duration,
    suspicion_threshold: f64,
}

impl FailureDetector {
    pub fn new(heartbeat_interval: Duration, timeout_duration: Duration) -> Self {
        Self {
            nodes: HashMap::new(),
            heartbeat_interval,
            timeout_duration,
            suspicion_threshold: 0.5,
        }
    }
    
    pub fn add_node(&mut self, node_id: NodeId) {
        let status = NodeStatus::new(node_id);
        self.nodes.insert(node_id, status);
    }
    
    pub fn receive_heartbeat(&mut self, node_id: NodeId) {
        if let Some(status) = self.nodes.get_mut(&node_id) {
            status.update_heartbeat();
        }
    }
    
    pub fn check_failures(&mut self) -> Vec<NodeId> {
        let mut failed_nodes = Vec::new();
        
        for (node_id, status) in &mut self.nodes {
            if status.is_failed(self.timeout_duration) {
                failed_nodes.push(*node_id);
            }
        }
        
        failed_nodes
    }
    
    pub fn get_suspicion_level(&self, node_id: NodeId) -> f64 {
        if let Some(status) = self.nodes.get(&node_id) {
            status.suspicion_level(self.timeout_duration)
        } else {
            0.0
        }
    }
}

pub struct NodeStatus {
    node_id: NodeId,
    last_heartbeat: Instant,
    heartbeat_count: u64,
    failure_count: u64,
}

impl NodeStatus {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            last_heartbeat: Instant::now(),
            heartbeat_count: 0,
            failure_count: 0,
        }
    }
    
    pub fn update_heartbeat(&mut self) {
        self.last_heartbeat = Instant::now();
        self.heartbeat_count += 1;
    }
    
    pub fn is_failed(&self, timeout: Duration) -> bool {
        self.last_heartbeat.elapsed() > timeout
    }
    
    pub fn suspicion_level(&self, timeout: Duration) -> f64 {
        let elapsed = self.last_heartbeat.elapsed();
        if elapsed > timeout {
            let extra_time = elapsed - timeout;
            let timeout_secs = timeout.as_secs_f64();
            let extra_secs = extra_time.as_secs_f64();
            
            (extra_secs / timeout_secs).min(1.0)
        } else {
            0.0
        }
    }
}
```

### 3.2 故障恢复

**故障恢复机制**：

```rust
pub struct FaultRecovery {
    backup_nodes: HashMap<NodeId, BackupNode>,
    recovery_strategy: RecoveryStrategy,
    data_replication: DataReplication,
}

impl FaultRecovery {
    pub fn new() -> Self {
        Self {
            backup_nodes: HashMap::new(),
            recovery_strategy: RecoveryStrategy::ActiveBackup,
            data_replication: DataReplication::new(),
        }
    }
    
    pub fn handle_node_failure(&mut self, failed_node: NodeId) -> Result<(), RecoveryError> {
        match self.recovery_strategy {
            RecoveryStrategy::ActiveBackup => {
                self.active_backup_recovery(failed_node)
            },
            RecoveryStrategy::CheckpointRestore => {
                self.checkpoint_restore_recovery(failed_node)
            },
            RecoveryStrategy::StateTransfer => {
                self.state_transfer_recovery(failed_node)
            },
        }
    }
    
    fn active_backup_recovery(&mut self, failed_node: NodeId) -> Result<(), RecoveryError> {
        // 查找备份节点
        if let Some(backup) = self.backup_nodes.get(&failed_node) {
            // 激活备份节点
            backup.activate()?;
            
            // 同步数据
            self.data_replication.sync_to_backup(failed_node, backup.node_id)?;
            
            println!("备份节点 {} 已激活", backup.node_id);
            Ok(())
        } else {
            Err(RecoveryError::NoBackupAvailable)
        }
    }
    
    fn checkpoint_restore_recovery(&mut self, failed_node: NodeId) -> Result<(), RecoveryError> {
        // 从检查点恢复
        let checkpoint = self.load_latest_checkpoint(failed_node)?;
        
        // 创建新节点
        let new_node = self.create_replacement_node(failed_node)?;
        
        // 从检查点恢复状态
        new_node.restore_from_checkpoint(checkpoint)?;
        
        println!("节点 {} 已从检查点恢复", new_node.node_id);
        Ok(())
    }
    
    fn state_transfer_recovery(&mut self, failed_node: NodeId) -> Result<(), RecoveryError> {
        // 从其他节点传输状态
        let source_node = self.find_healthy_node()?;
        
        // 创建新节点
        let new_node = self.create_replacement_node(failed_node)?;
        
        // 传输状态
        self.transfer_state(source_node, new_node.node_id)?;
        
        println!("状态已从节点 {} 传输到新节点 {}", source_node, new_node.node_id);
        Ok(())
    }
    
    fn load_latest_checkpoint(&self, node_id: NodeId) -> Result<Checkpoint, RecoveryError> {
        // 加载最新的检查点
        let checkpoint_path = format!("checkpoints/{}.ckpt", node_id);
        
        // 在实际系统中，这里会从文件或数据库加载检查点
        Ok(Checkpoint::new(node_id, HashMap::new()))
    }
    
    fn create_replacement_node(&mut self, failed_node: NodeId) -> Result<BackupNode, RecoveryError> {
        let new_node_id = NodeId::new();
        let backup_node = BackupNode::new(new_node_id, failed_node);
        
        self.backup_nodes.insert(failed_node, backup_node.clone());
        Ok(backup_node)
    }
    
    fn find_healthy_node(&self) -> Result<NodeId, RecoveryError> {
        // 查找健康的节点
        for (node_id, backup) in &self.backup_nodes {
            if backup.is_healthy() {
                return Ok(*node_id);
            }
        }
        
        Err(RecoveryError::NoHealthyNode)
    }
    
    fn transfer_state(&self, source: NodeId, target: NodeId) -> Result<(), RecoveryError> {
        // 传输状态从源节点到目标节点
        println!("从节点 {} 传输状态到节点 {}", source, target);
        Ok(())
    }
}

pub struct BackupNode {
    node_id: NodeId,
    primary_node: NodeId,
    status: BackupStatus,
    data: HashMap<String, String>,
}

impl BackupNode {
    pub fn new(node_id: NodeId, primary_node: NodeId) -> Self {
        Self {
            node_id,
            primary_node,
            status: BackupStatus::Standby,
            data: HashMap::new(),
        }
    }
    
    pub fn activate(&mut self) -> Result<(), RecoveryError> {
        self.status = BackupStatus::Active;
        println!("备份节点 {} 已激活", self.node_id);
        Ok(())
    }
    
    pub fn is_healthy(&self) -> bool {
        self.status == BackupStatus::Active
    }
    
    pub fn restore_from_checkpoint(&mut self, checkpoint: Checkpoint) -> Result<(), RecoveryError> {
        self.data = checkpoint.data;
        self.status = BackupStatus::Active;
        Ok(())
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum BackupStatus {
    Standby,
    Active,
    Failed,
}

#[derive(Debug, Clone)]
pub enum RecoveryStrategy {
    ActiveBackup,
    CheckpointRestore,
    StateTransfer,
}

#[derive(Debug, Clone)]
pub struct Checkpoint {
    pub node_id: NodeId,
    pub data: HashMap<String, String>,
}

impl Checkpoint {
    pub fn new(node_id: NodeId, data: HashMap<String, String>) -> Self {
        Self { node_id, data }
    }
}
```

## 4. 分布式算法

### 4.1 共识算法

**Paxos共识算法**：

```rust
pub struct PaxosConsensus {
    proposers: HashMap<NodeId, Proposer>,
    acceptors: HashMap<NodeId, Acceptor>,
    learners: HashMap<NodeId, Learner>,
    quorum_size: usize,
}

impl PaxosConsensus {
    pub fn new(quorum_size: usize) -> Self {
        Self {
            proposers: HashMap::new(),
            acceptors: HashMap::new(),
            learners: HashMap::new(),
            quorum_size,
        }
    }
    
    pub fn propose_value(&mut self, proposer_id: NodeId, value: String) -> Result<(), ConsensusError> {
        let proposer = self.proposers.get_mut(&proposer_id)
            .ok_or(ConsensusError::ProposerNotFound)?;
        
        // 阶段1：准备
        let prepare_responses = self.prepare_phase(proposer_id)?;
        
        if prepare_responses.len() >= self.quorum_size {
            // 阶段2：接受
            let accept_responses = self.accept_phase(proposer_id, value, prepare_responses)?;
            
            if accept_responses.len() >= self.quorum_size {
                // 阶段3：学习
                self.learn_phase(proposer_id, value)?;
                Ok(())
            } else {
                Err(ConsensusError::AcceptQuorumNotReached)
            }
        } else {
            Err(ConsensusError::PrepareQuorumNotReached)
        }
    }
    
    fn prepare_phase(&self, proposer_id: NodeId) -> Result<Vec<PrepareResponse>, ConsensusError> {
        let mut responses = Vec::new();
        
        for acceptor in self.acceptors.values() {
            if let Ok(response) = acceptor.prepare(proposer_id) {
                responses.push(response);
            }
        }
        
        Ok(responses)
    }
    
    fn accept_phase(&mut self, proposer_id: NodeId, value: String, prepare_responses: Vec<PrepareResponse>) -> Result<Vec<AcceptResponse>, ConsensusError> {
        let mut responses = Vec::new();
        
        for acceptor in self.acceptors.values_mut() {
            if let Ok(response) = acceptor.accept(proposer_id, value.clone()) {
                responses.push(response);
            }
        }
        
        Ok(responses)
    }
    
    fn learn_phase(&mut self, proposer_id: NodeId, value: String) -> Result<(), ConsensusError> {
        for learner in self.learners.values_mut() {
            learner.learn(proposer_id, value.clone())?;
        }
        Ok(())
    }
}

pub struct Proposer {
    node_id: NodeId,
    proposal_number: u64,
    proposed_value: Option<String>,
}

impl Proposer {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            proposal_number: 0,
            proposed_value: None,
        }
    }
    
    pub fn prepare(&mut self) -> PrepareRequest {
        self.proposal_number += 1;
        PrepareRequest {
            proposer_id: self.node_id,
            proposal_number: self.proposal_number,
        }
    }
    
    pub fn accept(&mut self, value: String) -> AcceptRequest {
        self.proposed_value = Some(value.clone());
        AcceptRequest {
            proposer_id: self.node_id,
            proposal_number: self.proposal_number,
            value,
        }
    }
}

pub struct Acceptor {
    node_id: NodeId,
    promised_proposal: Option<u64>,
    accepted_proposal: Option<u64>,
    accepted_value: Option<String>,
}

impl Acceptor {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            promised_proposal: None,
            accepted_proposal: None,
            accepted_value: None,
        }
    }
    
    pub fn prepare(&mut self, request: PrepareRequest) -> Result<PrepareResponse, ConsensusError> {
        if let Some(promised) = self.promised_proposal {
            if request.proposal_number <= promised {
                return Err(ConsensusError::ProposalNumberTooLow);
            }
        }
        
        self.promised_proposal = Some(request.proposal_number);
        
        Ok(PrepareResponse {
            acceptor_id: self.node_id,
            promised_proposal: self.promised_proposal,
            accepted_proposal: self.accepted_proposal,
            accepted_value: self.accepted_value.clone(),
        })
    }
    
    pub fn accept(&mut self, request: AcceptRequest) -> Result<AcceptResponse, ConsensusError> {
        if let Some(promised) = self.promised_proposal {
            if request.proposal_number < promised {
                return Err(ConsensusError::ProposalNumberTooLow);
            }
        }
        
        self.promised_proposal = Some(request.proposal_number);
        self.accepted_proposal = Some(request.proposal_number);
        self.accepted_value = Some(request.value.clone());
        
        Ok(AcceptResponse {
            acceptor_id: self.node_id,
            proposal_number: request.proposal_number,
        })
    }
}

pub struct Learner {
    node_id: NodeId,
    learned_values: Vec<String>,
}

impl Learner {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            learned_values: Vec::new(),
        }
    }
    
    pub fn learn(&mut self, proposer_id: NodeId, value: String) -> Result<(), ConsensusError> {
        self.learned_values.push(value);
        println!("学习者 {} 学习到值: {}", self.node_id, value);
        Ok(())
    }
}

#[derive(Debug, Clone)]
pub struct PrepareRequest {
    pub proposer_id: NodeId,
    pub proposal_number: u64,
}

#[derive(Debug, Clone)]
pub struct PrepareResponse {
    pub acceptor_id: NodeId,
    pub promised_proposal: Option<u64>,
    pub accepted_proposal: Option<u64>,
    pub accepted_value: Option<String>,
}

#[derive(Debug, Clone)]
pub struct AcceptRequest {
    pub proposer_id: NodeId,
    pub proposal_number: u64,
    pub value: String,
}

#[derive(Debug, Clone)]
pub struct AcceptResponse {
    pub acceptor_id: NodeId,
    pub proposal_number: u64,
}
```

## 5. 分布式存储

### 5.1 数据分片

**数据分片实现**：

```rust
pub struct DataSharding {
    shards: HashMap<ShardId, Shard>,
    shard_map: ShardMap,
    rebalancer: ShardRebalancer,
}

impl DataSharding {
    pub fn new(shard_count: usize) -> Self {
        let mut shards = HashMap::new();
        let shard_map = ShardMap::new(shard_count);
        let rebalancer = ShardRebalancer::new();
        
        for i in 0..shard_count {
            let shard_id = ShardId::new(i);
            shards.insert(shard_id, Shard::new(shard_id));
        }
        
        Self {
            shards,
            shard_map,
            rebalancer,
        }
    }
    
    pub fn write(&mut self, key: String, value: String) -> Result<(), StorageError> {
        let shard_id = self.shard_map.get_shard_for_key(&key);
        let shard = self.shards.get_mut(&shard_id)
            .ok_or(StorageError::ShardNotFound)?;
        
        shard.write(key, value)
    }
    
    pub fn read(&self, key: &str) -> Result<String, StorageError> {
        let shard_id = self.shard_map.get_shard_for_key(key);
        let shard = self.shards.get(&shard_id)
            .ok_or(StorageError::ShardNotFound)?;
        
        shard.read(key)
    }
    
    pub fn add_shard(&mut self) -> ShardId {
        let new_shard_id = ShardId::new(self.shards.len());
        self.shards.insert(new_shard_id, Shard::new(new_shard_id));
        
        // 重新平衡数据
        self.rebalancer.rebalance(&mut self.shards, &mut self.shard_map);
        
        new_shard_id
    }
    
    pub fn remove_shard(&mut self, shard_id: ShardId) -> Result<(), StorageError> {
        if let Some(shard) = self.shards.remove(&shard_id) {
            // 重新分配数据
            self.rebalancer.redistribute_data(shard, &mut self.shards);
            Ok(())
        } else {
            Err(StorageError::ShardNotFound)
        }
    }
}

pub struct Shard {
    id: ShardId,
    data: HashMap<String, String>,
    capacity: usize,
}

impl Shard {
    pub fn new(id: ShardId) -> Self {
        Self {
            id,
            data: HashMap::new(),
            capacity: 1000,
        }
    }
    
    pub fn write(&mut self, key: String, value: String) -> Result<(), StorageError> {
        if self.data.len() >= self.capacity {
            return Err(StorageError::ShardFull);
        }
        
        self.data.insert(key, value);
        Ok(())
    }
    
    pub fn read(&self, key: &str) -> Result<String, StorageError> {
        self.data.get(key)
            .cloned()
            .ok_or(StorageError::KeyNotFound)
    }
    
    pub fn get_all_data(&self) -> HashMap<String, String> {
        self.data.clone()
    }
}

pub struct ShardMap {
    shard_count: usize,
    hash_function: Box<dyn Fn(&str) -> u64>,
}

impl ShardMap {
    pub fn new(shard_count: usize) -> Self {
        Self {
            shard_count,
            hash_function: Box::new(|key| {
                use std::collections::hash_map::DefaultHasher;
                use std::hash::{Hash, Hasher};
                
                let mut hasher = DefaultHasher::new();
                key.hash(&mut hasher);
                hasher.finish()
            }),
        }
    }
    
    pub fn get_shard_for_key(&self, key: &str) -> ShardId {
        let hash = (self.hash_function)(key);
        let shard_index = (hash % self.shard_count as u64) as usize;
        ShardId::new(shard_index)
    }
}

pub struct ShardRebalancer {
    rebalance_threshold: f64,
}

impl ShardRebalancer {
    pub fn new() -> Self {
        Self {
            rebalance_threshold: 0.2, // 20% 不平衡阈值
        }
    }
    
    pub fn rebalance(&self, shards: &mut HashMap<ShardId, Shard>, shard_map: &mut ShardMap) {
        let total_items = shards.values().map(|s| s.data.len()).sum::<usize>();
        let avg_items = total_items / shards.len();
        
        for shard in shards.values() {
            let load_ratio = shard.data.len() as f64 / avg_items as f64;
            
            if (load_ratio - 1.0).abs() > self.rebalance_threshold {
                // 需要重新平衡
                self.perform_rebalance(shards, shard_map);
                break;
            }
        }
    }
    
    fn perform_rebalance(&self, shards: &mut HashMap<ShardId, Shard>, _shard_map: &mut ShardMap) {
        // 实现重新平衡逻辑
        println!("执行分片重新平衡");
    }
    
    pub fn redistribute_data(&self, removed_shard: Shard, target_shards: &mut HashMap<ShardId, Shard>) {
        let data = removed_shard.get_all_data();
        
        for (key, value) in data {
            // 找到目标分片
            let target_shard_id = self.find_target_shard(&key, target_shards);
            
            if let Some(target_shard) = target_shards.get_mut(&target_shard_id) {
                let _ = target_shard.write(key, value);
            }
        }
    }
    
    fn find_target_shard(&self, key: &str, shards: &HashMap<ShardId, Shard>) -> ShardId {
        // 简单的目标分片选择策略
        let shard_count = shards.len();
        let hash = {
            use std::collections::hash_map::DefaultHasher;
            use std::hash::{Hash, Hasher};
            
            let mut hasher = DefaultHasher::new();
            key.hash(&mut hasher);
            hasher.finish()
        };
        
        let shard_index = (hash % shard_count as u64) as usize;
        ShardId::new(shard_index)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct ShardId(usize);

impl ShardId {
    pub fn new(id: usize) -> Self {
        Self(id)
    }
}
```

### 5.2 数据复制

**数据复制实现**：

```rust
pub struct DataReplication {
    replicas: HashMap<NodeId, Replica>,
    replication_factor: usize,
    consistency_level: ConsistencyLevel,
}

impl DataReplication {
    pub fn new(replication_factor: usize) -> Self {
        Self {
            replicas: HashMap::new(),
            replication_factor,
            consistency_level: ConsistencyLevel::Quorum,
        }
    }
    
    pub fn write(&mut self, key: String, value: String) -> Result<(), StorageError> {
        let mut success_count = 0;
        let required_count = self.get_required_replica_count();
        
        for replica in self.replicas.values_mut() {
            if replica.write(&key, &value).is_ok() {
                success_count += 1;
                
                if success_count >= required_count {
                    return Ok(());
                }
            }
        }
        
        Err(StorageError::InsufficientReplicas)
    }
    
    pub fn read(&self, key: &str) -> Result<String, StorageError> {
        let mut responses = Vec::new();
        let required_count = self.get_required_replica_count();
        
        for replica in self.replicas.values() {
            if let Ok(value) = replica.read(key) {
                responses.push(value);
                
                if responses.len() >= required_count {
                    return self.resolve_read_responses(responses);
                }
            }
        }
        
        Err(StorageError::InsufficientReplicas)
    }
    
    fn get_required_replica_count(&self) -> usize {
        match self.consistency_level {
            ConsistencyLevel::One => 1,
            ConsistencyLevel::Quorum => (self.replicas.len() / 2) + 1,
            ConsistencyLevel::All => self.replicas.len(),
        }
    }
    
    fn resolve_read_responses(&self, responses: Vec<String>) -> Result<String, StorageError> {
        if responses.is_empty() {
            return Err(StorageError::NoResponses);
        }
        
        // 简单的响应解析：返回第一个响应
        // 在实际系统中，这里会实现更复杂的冲突解决
        Ok(responses[0].clone())
    }
    
    pub fn add_replica(&mut self, node_id: NodeId) {
        let replica = Replica::new(node_id);
        self.replicas.insert(node_id, replica);
    }
    
    pub fn remove_replica(&mut self, node_id: NodeId) -> Result<(), StorageError> {
        if self.replicas.len() <= self.replication_factor {
            return Err(StorageError::TooFewReplicas);
        }
        
        self.replicas.remove(&node_id);
        Ok(())
    }
}

pub struct Replica {
    node_id: NodeId,
    data: HashMap<String, String>,
    version: u64,
}

impl Replica {
    pub fn new(node_id: NodeId) -> Self {
        Self {
            node_id,
            data: HashMap::new(),
            version: 0,
        }
    }
    
    pub fn write(&mut self, key: &str, value: &str) -> Result<(), StorageError> {
        self.data.insert(key.to_string(), value.to_string());
        self.version += 1;
        Ok(())
    }
    
    pub fn read(&self, key: &str) -> Result<String, StorageError> {
        self.data.get(key)
            .cloned()
            .ok_or(StorageError::KeyNotFound)
    }
    
    pub fn get_version(&self) -> u64 {
        self.version
    }
}

#[derive(Debug, Clone)]
pub enum ConsistencyLevel {
    One,
    Quorum,
    All,
}
```

## 6. 总结

分布式系统理论为大规模系统提供了强大的理论基础。通过一致性理论、容错机制、分布式算法和分布式存储的有机结合，我们能够：

1. **数据一致性**：通过强一致性和最终一致性保证数据正确性
2. **系统容错**：通过故障检测和恢复机制提高系统可用性
3. **共识达成**：通过Paxos等算法实现分布式共识
4. **数据管理**：通过分片和复制实现高效的数据存储

分布式系统理论与软件架构理论的其他分支形成了完整的理论体系，为大规模分布式系统的设计和实现提供了强大的理论基础。
