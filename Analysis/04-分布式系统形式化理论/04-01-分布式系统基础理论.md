# 04-01 分布式系统基础理论

## 目录

1. [1.0 分布式系统模型](#10-分布式系统模型)
2. [2.0 故障模型](#20-故障模型)
3. [3.0 一致性理论](#30-一致性理论)
4. [4.0 共识算法](#40-共识算法)
5. [5.0 复制状态机](#50-复制状态机)
6. [6.0 分布式存储](#60-分布式存储)
7. [7.0 时钟同步](#70-时钟同步)
8. [8.0 实际应用](#80-实际应用)

## 1.0 分布式系统模型

### 1.1 系统形式化定义

**定义 1.1.1 (分布式系统)**
分布式系统是一个五元组 $\mathcal{DS} = (\mathcal{N}, \mathcal{C}, \mathcal{M}, \mathcal{T}, \mathcal{F})$，其中：

- $\mathcal{N} = \{p_1, p_2, \ldots, p_n\}$ 是节点集合 (Nodes)
- $\mathcal{C} \subseteq \mathcal{N} \times \mathcal{N}$ 是通信关系 (Communication)
- $\mathcal{M}$ 是消息传递机制 (Message Passing)
- $\mathcal{T}$ 是时间模型 (Time Model)
- $\mathcal{F}$ 是故障模型 (Failure Model)

**定义 1.1.2 (节点状态)**
节点 $p_i$ 的状态是一个三元组 $s_i = (local\_state_i, messages_i, clock_i)$，其中：

- $local\_state_i$ 是本地状态
- $messages_i$ 是消息队列
- $clock_i$ 是本地时钟

**定义 1.1.3 (系统配置)**
系统配置 $C$ 是所有节点状态的集合：
$$C = \{s_1, s_2, \ldots, s_n\}$$

### 1.2 时间模型

**定义 1.2.1 (异步系统)**
异步分布式系统中：

- 消息传递延迟无界但有限：$\forall m \in \mathcal{M} \cdot \exists d \cdot \text{delay}(m) \leq d$
- 节点处理时间无界但有限：$\forall p \in \mathcal{N} \cdot \exists t \cdot \text{process\_time}(p) \leq t$
- 不存在全局时钟：$\not\exists c \cdot \forall p \in \mathcal{N} \cdot \text{clock}(p) = c$

**定义 1.2.2 (同步系统)**
同步分布式系统中：

- 消息传递延迟有界：$\exists d \cdot \forall m \in \mathcal{M} \cdot \text{delay}(m) \leq d$
- 节点处理时间有界：$\exists t \cdot \forall p \in \mathcal{N} \cdot \text{process\_time}(p) \leq t$
- 存在全局时钟或同步轮次：$\exists c \cdot \forall p \in \mathcal{N} \cdot \text{clock}(p) = c$

**定义 1.2.3 (部分同步系统)**
部分同步系统中：

- 消息传递延迟有界但未知：$\exists d \cdot \forall m \in \mathcal{M} \cdot \text{delay}(m) \leq d$
- 节点处理时间有界但未知：$\exists t \cdot \forall p \in \mathcal{N} \cdot \text{process\_time}(p) \leq t$
- 时钟漂移有界：$\exists \delta \cdot \forall p, q \in \mathcal{N} \cdot |\text{clock}(p) - \text{clock}(q)| \leq \delta$

### 1.3 消息传递模型

**定义 1.3.1 (消息)**
消息是一个四元组 $m = (sender, receiver, content, timestamp)$，其中：

- $sender \in \mathcal{N}$ 是发送者
- $receiver \in \mathcal{N}$ 是接收者
- $content$ 是消息内容
- $timestamp$ 是时间戳

**定义 1.3.2 (消息传递)**
消息传递函数 $send : \mathcal{N} \times \mathcal{N} \times \text{Content} \rightarrow \mathcal{M}$：
$$send(p_i, p_j, content) = (p_i, p_j, content, \text{clock}(p_i))$$

**定义 1.3.3 (消息接收)**
消息接收函数 $receive : \mathcal{N} \times \mathcal{M} \rightarrow \text{State}$：
$$receive(p_i, m) = \text{update\_state}(p_i, m)$$

## 2.0 故障模型

### 2.1 故障类型

**定义 2.1.1 (崩溃故障)**
节点 $p_i$ 发生崩溃故障，如果：
$$\exists t \cdot \forall t' > t \cdot \text{state}(p_i, t') = \text{crashed}$$

**定义 2.1.2 (拜占庭故障)**
节点 $p_i$ 发生拜占庭故障，如果：
$$\exists t \cdot \forall t' > t \cdot \text{behavior}(p_i, t') \notin \text{correct\_behaviors}$$

**定义 2.1.3 (遗漏故障)**
节点 $p_i$ 发生遗漏故障，如果：
$$\exists m \in \text{messages\_to}(p_i) \cdot \text{receive}(p_i, m) = \bot$$

**定义 2.1.4 (时序故障)**
节点 $p_i$ 发生时序故障，如果：
$$\exists t \cdot |\text{clock}(p_i, t) - \text{global\_time}(t)| > \delta$$

### 2.2 故障假设

**定义 2.2.1 (故障假设)**
故障假设 $\mathcal{F}$ 是一个三元组 $(f, \text{type}, \text{pattern})$，其中：

- $f$ 是最大故障节点数
- $\text{type} \in \{\text{crash}, \text{byzantine}, \text{omission}, \text{timing}\}$
- $\text{pattern} \in \{\text{static}, \text{dynamic}\}$

**定理 2.2.1 (故障边界)**
在 $n$ 个节点的系统中，最多可以容忍 $f$ 个故障节点，其中：

- 崩溃故障：$f < n$
- 拜占庭故障：$f < n/3$
- 遗漏故障：$f < n/2$

**证明：** 通过反证法：

1. **崩溃故障**：假设 $f \geq n$，则所有节点都可能崩溃，无法达成共识
2. **拜占庭故障**：假设 $f \geq n/3$，则故障节点可能阻止正确节点达成共识
3. **遗漏故障**：假设 $f \geq n/2$，则故障节点可能阻止多数节点通信

## 3.0 一致性理论

### 3.1 一致性定义

**定义 3.1.1 (一致性)**
系统满足一致性，如果：
$$\forall p_i, p_j \in \text{correct\_nodes} \cdot \text{decision}(p_i) = \text{decision}(p_j)$$

**定义 3.1.2 (有效性)**
系统满足有效性，如果：
$$\text{if } \forall p_i \in \text{correct\_nodes} \cdot \text{propose}(p_i) = v \text{ then } \text{decision} = v$$

**定义 3.1.3 (终止性)**
系统满足终止性，如果：
$$\forall p_i \in \text{correct\_nodes} \cdot \exists t \cdot \text{decision}(p_i, t) \neq \bot$$

### 3.2 不可能性结果

**定理 3.2.1 (FLP不可能性)**
在异步系统中，即使只有一个节点崩溃，也无法实现确定性共识。

**证明：** 通过构造性证明：

1. **假设**：存在确定性共识算法 $A$
2. **构造执行**：构造一个执行序列，使得算法无法终止
3. **矛盾**：违反终止性，得出矛盾

**定义 3.2.1 (FLP执行)**
FLP执行是一个无限序列 $E = e_1, e_2, \ldots$，其中每个 $e_i$ 是：

- 消息传递事件
- 节点处理事件
- 故障事件

**定理 3.2.2 (CAP定理)**
在分布式系统中，最多只能同时满足以下三个性质中的两个：

- **一致性 (Consistency)**：所有节点看到相同的数据
- **可用性 (Availability)**：每个请求都能得到响应
- **分区容错性 (Partition Tolerance)**：网络分区时系统仍能工作

**证明：** 通过构造性证明：

1. 假设同时满足CAP三个性质
2. 构造网络分区场景
3. 证明无法同时满足一致性和可用性

## 4.0 共识算法

### 4.1 Paxos算法

**定义 4.1.1 (Paxos状态)**
Paxos节点状态是一个四元组 $s = (\text{proposal\_number}, \text{accepted\_value}, \text{accepted\_number}, \text{role})$，其中：

- $\text{proposal\_number}$ 是提议编号
- $\text{accepted\_value}$ 是已接受的值
- $\text{accepted\_number}$ 是已接受的编号
- $\text{role} \in \{\text{proposer}, \text{acceptor}, \text{learner}\}$

**定义 4.1.2 (Paxos阶段)**
Paxos算法包含两个阶段：

1. **阶段1a (Prepare)**：提议者发送准备请求
2. **阶段1b (Promise)**：接受者响应准备请求
3. **阶段2a (Accept)**：提议者发送接受请求
4. **阶段2b (Accepted)**：接受者响应接受请求

**算法 4.1.1 (Paxos算法)**
```rust
struct PaxosState {
    proposal_number: u64,
    accepted_value: Option<Value>,
    accepted_number: u64,
    role: Role,
}

enum Role {
    Proposer,
    Acceptor,
    Learner,
}

impl PaxosState {
    // 阶段1a: 准备阶段
    fn phase1a(&mut self, n: u64) -> Vec<Message> {
        self.proposal_number = n;
        vec![Message::Prepare(n)]
    }

    // 阶段1b: 承诺阶段
    fn phase1b(&mut self, n: u64, promised_num: u64, accepted_val: Option<Value>, accepted_num: u64) -> Message {
        if n > promised_num {
            Message::Promise(n, accepted_num, accepted_val)
        } else {
            Message::Nack
        }
    }

    // 阶段2a: 接受阶段
    fn phase2a(&mut self, n: u64, v: Value) -> Vec<Message> {
        vec![Message::Accept(n, v)]
    }

    // 阶段2b: 接受响应
    fn phase2b(&mut self, n: u64, v: Value) -> Message {
        if n >= self.proposal_number {
            self.accepted_value = Some(v);
            self.accepted_number = n;
            Message::Accepted(n, v)
        } else {
            Message::Nack
        }
    }
}
```

**定理 4.1.1 (Paxos正确性)**
Paxos算法满足共识的所有性质。

**证明：** 通过归纳法：

1. **一致性**：通过提议编号保证，只有最高编号的提议被接受
2. **有效性**：通过提议值选择保证，如果所有节点提议相同值，则选择该值
3. **终止性**：通过活锁避免机制保证，最终会达成共识

### 4.2 Raft算法

**定义 4.2.1 (Raft状态)**
Raft节点状态是一个五元组 $s = (\text{term}, \text{state}, \text{voted\_for}, \text{log}, \text{commit\_index})$，其中：

- $\text{term}$ 是当前任期
- $\text{state} \in \{\text{follower}, \text{candidate}, \text{leader}\}$
- $\text{voted\_for}$ 是投票给哪个节点
- $\text{log}$ 是日志条目
- $\text{commit\_index}$ 是已提交的索引

**定义 4.2.2 (Raft领导者选举)**
Raft领导者选举过程：

1. **超时**：跟随者超时后成为候选人
2. **投票请求**：候选人向其他节点请求投票
3. **投票响应**：节点投票给候选人
4. **成为领导者**：获得多数票的候选人成为领导者

**算法 4.2.1 (Raft领导者选举)**
```rust
struct RaftState {
    term: u64,
    state: NodeState,
    voted_for: Option<NodeId>,
    log: Vec<LogEntry>,
    commit_index: u64,
}

enum NodeState {
    Follower,
    Candidate,
    Leader,
}

impl RaftState {
    // 开始选举
    fn start_election(&mut self) -> Vec<Message> {
        self.state = NodeState::Candidate;
        self.term += 1;
        self.voted_for = Some(self.node_id);
        
        vec![Message::RequestVote {
            term: self.term,
            candidate_id: self.node_id,
            last_log_index: self.log.len() as u64,
            last_log_term: self.log.last().map(|e| e.term).unwrap_or(0),
        }]
    }

    // 处理投票请求
    fn handle_request_vote(&mut self, term: u64, candidate_id: NodeId, last_log_index: u64, last_log_term: u64) -> Message {
        if term < self.term {
            return Message::RequestVoteResponse { term: self.term, vote_granted: false };
        }
        
        if term > self.term {
            self.term = term;
            self.state = NodeState::Follower;
            self.voted_for = None;
        }
        
        if self.voted_for.is_none() || self.voted_for == Some(candidate_id) {
            if self.is_log_up_to_date(last_log_index, last_log_term) {
                self.voted_for = Some(candidate_id);
                return Message::RequestVoteResponse { term: self.term, vote_granted: true };
            }
        }
        
        Message::RequestVoteResponse { term: self.term, vote_granted: false }
    }

    // 检查日志是否最新
    fn is_log_up_to_date(&self, last_log_index: u64, last_log_term: u64) -> bool {
        let last_term = self.log.last().map(|e| e.term).unwrap_or(0);
        last_log_term > last_term || (last_log_term == last_term && last_log_index >= self.log.len() as u64)
    }
}
```

**定理 4.2.1 (Raft安全性)**
Raft算法保证在任何时刻最多只有一个领导者。

**证明：** 通过投票机制：

1. **任期唯一性**：每个任期最多一个领导者
2. **投票约束**：每个节点每个任期最多投一票
3. **多数要求**：需要多数票才能成为领导者

## 5.0 复制状态机

### 5.1 状态机定义

**定义 5.1.1 (复制状态机)**
复制状态机是一个四元组 $\mathcal{RSM} = (\mathcal{S}, \Sigma, \delta, s_0)$，其中：

- $\mathcal{S}$ 是状态集合
- $\Sigma$ 是输入字母表
- $\delta : \mathcal{S} \times \Sigma \rightarrow \mathcal{S}$ 是状态转移函数
- $s_0 \in \mathcal{S}$ 是初始状态

**定义 5.1.2 (日志条目)**
日志条目是一个三元组 $e = (\text{term}, \text{index}, \text{command})$，其中：

- $\text{term}$ 是创建条目的任期
- $\text{index}$ 是条目的索引
- $\text{command}$ 是命令内容

**定义 5.1.3 (日志一致性)**
两个日志 $\text{Log}_i$ 和 $\text{Log}_j$ 一致，如果：
$$\forall k \cdot \text{Log}_i[k].\text{term} = \text{Log}_j[k].\text{term} \Rightarrow \text{Log}_i[k].\text{command} = \text{Log}_j[k].\text{command}$$

### 5.2 日志复制

**定义 5.2.1 (日志复制)**
日志复制确保所有节点执行相同操作序列：
$$\text{Log}_i = [e_1, e_2, \ldots, e_n]$$

**定理 5.2.1 (日志一致性)**
如果两个节点的日志在相同索引处有相同任期，则包含相同命令。

**证明：** 通过领导者唯一性：

1. 每个任期最多一个领导者
2. 领导者创建日志条目
3. 日志条目一旦创建就不会改变

**算法 5.2.1 (日志复制)**
```rust
struct LogEntry {
    term: u64,
    index: u64,
    command: Command,
}

struct ReplicatedStateMachine {
    log: Vec<LogEntry>,
    commit_index: u64,
    last_applied: u64,
}

impl ReplicatedStateMachine {
    // 添加日志条目
    fn append_entry(&mut self, term: u64, command: Command) -> u64 {
        let index = self.log.len() as u64;
        self.log.push(LogEntry { term, index, command });
        index
    }

    // 应用日志条目
    fn apply_entries(&mut self) {
        while self.last_applied < self.commit_index {
            self.last_applied += 1;
            let entry = &self.log[self.last_applied as usize];
            self.apply_command(&entry.command);
        }
    }

    // 应用命令
    fn apply_command(&mut self, command: &Command) {
        match command {
            Command::Set { key, value } => {
                // 应用设置命令
            }
            Command::Delete { key } => {
                // 应用删除命令
            }
        }
    }
}
```

## 6.0 分布式存储

### 6.1 一致性哈希

**定义 6.1.1 (一致性哈希)**
一致性哈希是一个函数 $h : \text{Key} \rightarrow \text{Node}$，满足：

1. **平衡性**：节点负载均衡
2. **单调性**：节点增减时数据迁移最小
3. **分散性**：相同数据映射到不同节点

**定义 6.1.2 (虚拟节点)**
虚拟节点是物理节点的多个副本，用于改善负载均衡：
$$\text{virtual\_nodes}(n) = \{n_1, n_2, \ldots, n_k\}$$

**算法 6.1.1 (一致性哈希)**
```rust
use std::collections::BTreeMap;
use std::hash::{Hash, Hasher};

struct ConsistentHash {
    ring: BTreeMap<u64, NodeId>,
    virtual_nodes: usize,
}

impl ConsistentHash {
    fn new(virtual_nodes: usize) -> Self {
        Self {
            ring: BTreeMap::new(),
            virtual_nodes,
        }
    }

    // 添加节点
    fn add_node(&mut self, node_id: NodeId) {
        for i in 0..self.virtual_nodes {
            let virtual_node_id = format!("{}#{}", node_id, i);
            let hash = self.hash(&virtual_node_id);
            self.ring.insert(hash, node_id);
        }
    }

    // 移除节点
    fn remove_node(&mut self, node_id: NodeId) {
        let mut to_remove = Vec::new();
        for (hash, id) in &self.ring {
            if *id == node_id {
                to_remove.push(*hash);
            }
        }
        for hash in to_remove {
            self.ring.remove(&hash);
        }
    }

    // 查找节点
    fn get_node(&self, key: &str) -> Option<NodeId> {
        let hash = self.hash(key);
        self.ring.range(hash..).next()
            .or_else(|| self.ring.iter().next())
            .map(|(_, node_id)| *node_id)
    }

    // 哈希函数
    fn hash(&self, key: &str) -> u64 {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish()
    }
}
```

### 6.2 分布式事务

**定义 6.2.1 (分布式事务)**
分布式事务是一个四元组 $\mathcal{DT} = (\text{operations}, \text{participants}, \text{coordinator}, \text{protocol})$，其中：

- $\text{operations}$ 是操作集合
- $\text{participants}$ 是参与者节点
- $\text{coordinator}$ 是协调者节点
- $\text{protocol}$ 是事务协议

**定义 6.2.2 (两阶段提交)**
两阶段提交协议：

1. **准备阶段**：协调者询问所有参与者是否准备提交
2. **提交阶段**：协调者根据参与者响应决定提交或回滚

**算法 6.2.1 (两阶段提交)**
```rust
enum TransactionState {
    Initial,
    Prepared,
    Committed,
    Aborted,
}

struct TwoPhaseCommit {
    state: TransactionState,
    participants: Vec<NodeId>,
    coordinator: NodeId,
}

impl TwoPhaseCommit {
    // 开始事务
    fn begin(&mut self) -> Vec<Message> {
        self.state = TransactionState::Initial;
        vec![Message::Prepare { transaction_id: self.transaction_id }]
    }

    // 处理准备响应
    fn handle_prepare_response(&mut self, participant: NodeId, prepared: bool) -> Option<Vec<Message>> {
        if !prepared {
            self.state = TransactionState::Aborted;
            return Some(vec![Message::Abort { transaction_id: self.transaction_id }]);
        }

        // 检查是否所有参与者都准备就绪
        if self.all_prepared() {
            self.state = TransactionState::Committed;
            return Some(vec![Message::Commit { transaction_id: self.transaction_id }]);
        }

        None
    }

    // 检查是否所有参与者都准备就绪
    fn all_prepared(&self) -> bool {
        // 实现检查逻辑
        true
    }
}
```

## 7.0 时钟同步

### 7.1 时钟模型

**定义 7.1.1 (物理时钟)**
物理时钟 $C(t)$ 是时间的单调递增函数：
$$C(t) = \alpha t + \beta$$

其中 $\alpha$ 是时钟漂移率，$\beta$ 是时钟偏移。

**定义 7.1.2 (逻辑时钟)**
逻辑时钟 $L(t)$ 是事件序的单调递增函数：
$$L(e_1) < L(e_2) \Rightarrow e_1 \text{ happens before } e_2$$

**定义 7.1.3 (向量时钟)**
向量时钟 $V_i$ 是节点 $i$ 的事件计数器向量：
$$V_i[j] = \text{number of events at node } j \text{ that causally precede current event at node } i$$

### 7.2 时钟同步算法

**定义 7.2.1 (时钟同步)**
时钟同步算法调整节点时钟，使得：
$$\forall i, j \in \mathcal{N} \cdot |C_i(t) - C_j(t)| \leq \delta$$

**算法 7.2.1 (Cristian算法)**
```rust
struct CristianClockSync {
    clock_offset: f64,
    round_trip_time: f64,
}

impl CristianClockSync {
    // 同步时钟
    fn sync_clock(&mut self, server_time: u64, request_time: u64, response_time: u64) {
        let round_trip = response_time - request_time;
        let estimated_server_time = server_time + round_trip / 2;
        let local_time = self.get_local_time();
        
        self.clock_offset = estimated_server_time as f64 - local_time as f64;
        self.round_trip_time = round_trip as f64;
    }

    // 获取同步时间
    fn get_synchronized_time(&self) -> u64 {
        let local_time = self.get_local_time();
        (local_time as f64 + self.clock_offset) as u64
    }

    // 获取本地时间
    fn get_local_time(&self) -> u64 {
        // 实现获取本地时间的逻辑
        0
    }
}
```

## 8.0 实际应用

### 8.1 Rust分布式系统实现

```rust
use tokio::sync::mpsc;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::{Duration, Instant};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Message {
    from: NodeId,
    to: NodeId,
    content: MessageContent,
    timestamp: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum MessageContent {
    RequestVote { term: u64, candidate_id: NodeId },
    RequestVoteResponse { term: u64, vote_granted: bool },
    AppendEntries { term: u64, leader_id: NodeId, entries: Vec<LogEntry> },
    AppendEntriesResponse { term: u64, success: bool },
}

#[derive(Debug, Clone)]
struct Node {
    id: NodeId,
    state: RaftState,
    peers: Vec<NodeId>,
    message_sender: mpsc::Sender<Message>,
    message_receiver: mpsc::Receiver<Message>,
}

impl Node {
    async fn run(&mut self) {
        let mut interval = tokio::time::interval(Duration::from_millis(100));
        
        loop {
            tokio::select! {
                _ = interval.tick() => {
                    self.tick().await;
                }
                message = self.message_receiver.recv() => {
                    if let Some(msg) = message {
                        self.handle_message(msg).await;
                    }
                }
            }
        }
    }

    async fn tick(&mut self) {
        match self.state.role {
            Role::Follower => {
                if self.state.election_timeout_elapsed() {
                    self.start_election().await;
                }
            }
            Role::Leader => {
                self.send_heartbeat().await;
            }
            Role::Candidate => {
                if self.state.election_timeout_elapsed() {
                    self.start_election().await;
                }
            }
        }
    }

    async fn start_election(&mut self) {
        self.state.role = Role::Candidate;
        self.state.term += 1;
        self.state.voted_for = Some(self.id);
        self.state.reset_election_timeout();

        let message = Message {
            from: self.id,
            to: NodeId::Broadcast,
            content: MessageContent::RequestVote {
                term: self.state.term,
                candidate_id: self.id,
            },
            timestamp: self.get_timestamp(),
        };

        self.broadcast_message(message).await;
    }

    async fn handle_message(&mut self, message: Message) {
        match message.content {
            MessageContent::RequestVote { term, candidate_id } => {
                self.handle_request_vote(term, candidate_id).await;
            }
            MessageContent::RequestVoteResponse { term, vote_granted } => {
                self.handle_request_vote_response(term, vote_granted).await;
            }
            MessageContent::AppendEntries { term, leader_id, entries } => {
                self.handle_append_entries(term, leader_id, entries).await;
            }
            MessageContent::AppendEntriesResponse { term, success } => {
                self.handle_append_entries_response(term, success).await;
            }
        }
    }

    async fn handle_request_vote(&mut self, term: u64, candidate_id: NodeId) {
        if term < self.state.term {
            return;
        }

        if term > self.state.term {
            self.state.term = term;
            self.state.role = Role::Follower;
            self.state.voted_for = None;
        }

        if self.state.voted_for.is_none() || self.state.voted_for == Some(candidate_id) {
            self.state.voted_for = Some(candidate_id);
            self.state.reset_election_timeout();

            let response = Message {
                from: self.id,
                to: candidate_id,
                content: MessageContent::RequestVoteResponse {
                    term: self.state.term,
                    vote_granted: true,
                },
                timestamp: self.get_timestamp(),
            };

            self.send_message(response).await;
        }
    }

    async fn broadcast_message(&self, message: Message) {
        for peer in &self.peers {
            let mut msg = message.clone();
            msg.to = *peer;
            let _ = self.message_sender.send(msg).await;
        }
    }

    async fn send_message(&self, message: Message) {
        let _ = self.message_sender.send(message).await;
    }

    fn get_timestamp(&self) -> u64 {
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64
    }
}

#[tokio::main]
async fn main() {
    // 创建分布式系统节点
    let mut nodes = Vec::new();
    
    for i in 0..3 {
        let (tx, rx) = mpsc::channel(100);
        let node = Node {
            id: NodeId(i),
            state: RaftState::new(),
            peers: vec![NodeId(0), NodeId(1), NodeId(2)],
            message_sender: tx,
            message_receiver: rx,
        };
        nodes.push(node);
    }

    // 启动所有节点
    let handles: Vec<_> = nodes.into_iter()
        .map(|mut node| tokio::spawn(async move { node.run().await }))
        .collect();

    // 等待所有节点完成
    for handle in handles {
        handle.await.unwrap();
    }
}
```

### 8.2 Go分布式系统实现

```go
package main

import (
    "context"
    "fmt"
    "log"
    "math/rand"
    "sync"
    "time"
)

// Node 分布式节点
type Node struct {
    ID        int
    state     *RaftState
    peers     []int
    messages  chan Message
    ctx       context.Context
    cancel    context.CancelFunc
    mu        sync.RWMutex
}

// NewNode 创建新节点
func NewNode(id int, peers []int) *Node {
    ctx, cancel := context.WithCancel(context.Background())
    return &Node{
        ID:       id,
        state:    NewRaftState(),
        peers:    peers,
        messages: make(chan Message, 100),
        ctx:      ctx,
        cancel:   cancel,
    }
}

// Start 启动节点
func (n *Node) Start() {
    go n.run()
    go n.electionTimer()
}

// run 主循环
func (n *Node) run() {
    ticker := time.NewTicker(100 * time.Millisecond)
    defer ticker.Stop()

    for {
        select {
        case <-n.ctx.Done():
            return
        case <-ticker.C:
            n.tick()
        case msg := <-n.messages:
            n.handleMessage(msg)
        }
    }
}

// tick 定时任务
func (n *Node) tick() {
    n.mu.Lock()
    defer n.mu.Unlock()

    switch n.state.Role {
    case Follower:
        if n.state.electionTimeoutElapsed() {
            n.startElection()
        }
    case Leader:
        n.sendHeartbeat()
    case Candidate:
        if n.state.electionTimeoutElapsed() {
            n.startElection()
        }
    }
}

// startElection 开始选举
func (n *Node) startElection() {
    n.state.Role = Candidate
    n.state.Term++
    n.state.VotedFor = n.ID
    n.state.resetElectionTimeout()

    msg := Message{
        From: n.ID,
        To:   Broadcast,
        Content: RequestVote{
            Term:        n.state.Term,
            CandidateID: n.ID,
        },
    }

    n.broadcastMessage(msg)
}

// handleMessage 处理消息
func (n *Node) handleMessage(msg Message) {
    n.mu.Lock()
    defer n.mu.Unlock()

    switch content := msg.Content.(type) {
    case RequestVote:
        n.handleRequestVote(content)
    case RequestVoteResponse:
        n.handleRequestVoteResponse(content)
    case AppendEntries:
        n.handleAppendEntries(content)
    case AppendEntriesResponse:
        n.handleAppendEntriesResponse(content)
    }
}

// handleRequestVote 处理投票请求
func (n *Node) handleRequestVote(req RequestVote) {
    if req.Term < n.state.Term {
        return
    }

    if req.Term > n.state.Term {
        n.state.Term = req.Term
        n.state.Role = Follower
        n.state.VotedFor = -1
    }

    if n.state.VotedFor == -1 || n.state.VotedFor == req.CandidateID {
        n.state.VotedFor = req.CandidateID
        n.state.resetElectionTimeout()

        response := Message{
            From: n.ID,
            To:   req.CandidateID,
            Content: RequestVoteResponse{
                Term:        n.state.Term,
                VoteGranted: true,
            },
        }

        n.sendMessage(response)
    }
}

// broadcastMessage 广播消息
func (n *Node) broadcastMessage(msg Message) {
    for _, peer := range n.peers {
        if peer != n.ID {
            msg.To = peer
            n.sendMessage(msg)
        }
    }
}

// sendMessage 发送消息
func (n *Node) sendMessage(msg Message) {
    // 在实际应用中，这里应该通过网络发送消息
    // 为了简化，我们直接发送到目标节点的消息通道
    if msg.To != Broadcast {
        // 这里应该实现实际的消息传递
        fmt.Printf("Node %d sending message to Node %d: %+v\n", n.ID, msg.To, msg.Content)
    }
}

// electionTimer 选举定时器
func (n *Node) electionTimer() {
    for {
        select {
        case <-n.ctx.Done():
            return
        case <-time.After(time.Duration(rand.Intn(300)+300) * time.Millisecond):
            n.mu.Lock()
            if n.state.Role == Follower && n.state.electionTimeoutElapsed() {
                n.startElection()
            }
            n.mu.Unlock()
        }
    }
}

// Stop 停止节点
func (n *Node) Stop() {
    n.cancel()
}

func main() {
    // 创建分布式系统
    nodes := make([]*Node, 3)
    peers := []int{0, 1, 2}

    for i := 0; i < 3; i++ {
        nodes[i] = NewNode(i, peers)
        nodes[i].Start()
    }

    // 运行一段时间
    time.Sleep(10 * time.Second)

    // 停止所有节点
    for _, node := range nodes {
        node.Stop()
    }

    fmt.Println("Distributed system stopped")
}
```

## 总结

分布式系统基础理论提供了一个严格的数学基础，确保：

1. **系统建模**：通过形式化模型描述分布式系统
2. **故障处理**：通过故障模型分析系统可靠性
3. **一致性保证**：通过共识算法实现数据一致性
4. **复制机制**：通过复制状态机保证系统可用性
5. **时钟同步**：通过时钟同步算法协调分布式时间

该理论为分布式系统的实际应用提供了坚实的理论基础，支持从理论到实践的完整开发流程。 