# 02-语法分析理论：语言结构的形式化分析

## 目录

1. [1.0 上下文无关文法](#10-上下文无关文法)
2. [2.0 语法分析算法](#20-语法分析算法)
3. [3.0 LR分析器](#30-lr分析器)
4. [4.0 语法树构建](#40-语法树构建)
5. [5.0 错误恢复](#50-错误恢复)
6. [6.0 语法优化](#60-语法优化)

## 1.0 上下文无关文法

### 1.1 文法定义

**定义 1.1.1 (上下文无关文法)**
上下文无关文法是一个四元组 $G = (V, \Sigma, P, S)$，其中：

- $V$ 是非终结符集合
- $\Sigma$ 是终结符集合，$V \cap \Sigma = \emptyset$
- $P$ 是产生式集合，$P \subseteq V \times (V \cup \Sigma)^*$
- $S \in V$ 是开始符号

**定义 1.1.2 (推导)**
对于产生式 $A \to \alpha$，定义直接推导关系：
$$\beta A \gamma \Rightarrow \beta \alpha \gamma$$

**定义 1.1.3 (语言)**
文法 $G$ 生成的语言定义为：
$$L(G) = \{w \in \Sigma^* \mid S \Rightarrow^* w\}$$

```rust
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct NonTerminal(String);

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Terminal(String);

#[derive(Debug, Clone)]
pub struct Production {
    left: NonTerminal,
    right: Vec<Symbol>,
}

#[derive(Debug, Clone)]
pub struct ContextFreeGrammar {
    non_terminals: Vec<NonTerminal>,
    terminals: Vec<Terminal>,
    productions: Vec<Production>,
    start_symbol: NonTerminal,
}

impl ContextFreeGrammar {
    pub fn new(non_terminals: Vec<NonTerminal>, terminals: Vec<Terminal>,
               productions: Vec<Production>, start_symbol: NonTerminal) -> Self {
        Self {
            non_terminals,
            terminals,
            productions,
            start_symbol,
        }
    }
    
    pub fn derive(&self, input: &str) -> bool {
        // 检查输入串是否可由文法生成
        let mut current = vec![Symbol::NonTerminal(self.start_symbol.clone())];
        
        // 简化实现：返回true
        true
    }
    
    pub fn is_ambiguous(&self) -> bool {
        // 检查文法是否歧义
        // 简化实现：返回false
        false
    }
}
```

### 1.2 文法分类

**定义 1.2.1 (Chomsky范式)**
文法 $G$ 是Chomsky范式，如果所有产生式都是以下形式之一：
- $A \to BC$，其中 $B, C \in V$
- $A \to a$，其中 $a \in \Sigma$

**定理 1.2.1 (Chomsky范式转换)**
对于任意上下文无关文法，存在等价的Chomsky范式文法。

**定义 1.2.2 (Greibach范式)**
文法 $G$ 是Greibach范式，如果所有产生式都是形式：
$$A \to a\alpha$$
其中 $a \in \Sigma$，$\alpha \in V^*$。

```rust
#[derive(Debug, Clone)]
pub struct GrammarNormalForm {
}

impl GrammarNormalForm {
    pub fn to_chomsky_normal_form(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 转换为Chomsky范式
        // 1. 消除ε产生式
        // 2. 消除单位产生式
        // 3. 将产生式转换为二元形式
        grammar.clone()
    }
    
    pub fn to_greibach_normal_form(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 转换为Greibach范式
        // 1. 转换为Chomsky范式
        // 2. 消除左递归
        // 3. 转换为Greibach范式
        grammar.clone()
    }
}
```

## 2.0 语法分析算法

### 2.1 递归下降分析

**定义 2.1.1 (递归下降分析器)**
递归下降分析器为每个非终结符实现一个函数。

```rust
#[derive(Debug, Clone)]
pub struct RecursiveDescentParser {
    grammar: ContextFreeGrammar,
    input: Vec<Terminal>,
    position: usize,
}

impl RecursiveDescentParser {
    pub fn new(grammar: ContextFreeGrammar) -> Self {
        Self {
            grammar,
            input: Vec::new(),
            position: 0,
        }
    }
    
    pub fn parse(&mut self, input: &str) -> Result<(), String> {
        self.input = input.chars().map(|c| Terminal(c.to_string())).collect();
        self.position = 0;
        
        self.parse_non_terminal(&self.grammar.start_symbol)
    }
    
    fn parse_non_terminal(&mut self, non_terminal: &NonTerminal) -> Result<(), String> {
        // 查找匹配的产生式
        for production in &self.grammar.productions {
            if production.left == *non_terminal {
                if self.try_production(production) {
                    return Ok(());
                }
            }
        }
        
        Err(format!("No valid production for {}", non_terminal.0))
    }
    
    fn try_production(&mut self, production: &Production) -> bool {
        let start_position = self.position;
        
        for symbol in &production.right {
            match symbol {
                Symbol::Terminal(term) => {
                    if self.position >= self.input.len() || 
                       self.input[self.position] != *term {
                        self.position = start_position;
                        return false;
                    }
                    self.position += 1;
                }
                Symbol::NonTerminal(non_term) => {
                    if self.parse_non_terminal(non_term).is_err() {
                        self.position = start_position;
                        return false;
                    }
                }
            }
        }
        
        true
    }
}
```

### 2.2 LL(1)分析

**定义 2.2.1 (FIRST集合)**
对于 $\alpha \in (V \cup \Sigma)^*$，FIRST($\alpha$)定义为：
$$\text{FIRST}(\alpha) = \{a \in \Sigma \mid \alpha \Rightarrow^* a\beta\} \cup \{\epsilon \mid \alpha \Rightarrow^* \epsilon\}$$

**定义 2.2.2 (FOLLOW集合)**
对于 $A \in V$，FOLLOW($A$)定义为：
$$\text{FOLLOW}(A) = \{a \in \Sigma \mid S \Rightarrow^* \alpha Aa\beta\} \cup \{\$ \mid S \Rightarrow^* \alpha A\}$$

**定义 2.2.3 (LL(1)条件)**
文法 $G$ 是LL(1)的，当且仅当对于任意产生式 $A \to \alpha \mid \beta$：
$$\text{FIRST}(\alpha) \cap \text{FIRST}(\beta) = \emptyset$$

```rust
#[derive(Debug, Clone)]
pub struct LL1Parser {
    grammar: ContextFreeGrammar,
    first_sets: HashMap<Symbol, HashSet<Terminal>>,
    follow_sets: HashMap<NonTerminal, HashSet<Terminal>>,
    parsing_table: HashMap<(NonTerminal, Terminal), Production>,
}

impl LL1Parser {
    pub fn new(grammar: ContextFreeGrammar) -> Result<Self, String> {
        let mut parser = Self {
            grammar,
            first_sets: HashMap::new(),
            follow_sets: HashMap::new(),
            parsing_table: HashMap::new(),
        };
        
        parser.compute_first_sets();
        parser.compute_follow_sets();
        parser.build_parsing_table()?;
        
        Ok(parser)
    }
    
    fn compute_first_sets(&mut self) {
        // 计算FIRST集合
        let mut changed = true;
        while changed {
            changed = false;
            
            for production in &self.grammar.productions {
                let first = self.first_of_sequence(&production.right);
                let key = Symbol::NonTerminal(production.left.clone());
                
                if let Some(existing) = self.first_sets.get_mut(&key) {
                    let old_size = existing.len();
                    existing.extend(first);
                    if existing.len() > old_size {
                        changed = true;
                    }
                } else {
                    self.first_sets.insert(key, first);
                    changed = true;
                }
            }
        }
    }
    
    fn first_of_sequence(&self, sequence: &[Symbol]) -> HashSet<Terminal> {
        let mut result = HashSet::new();
        
        for symbol in sequence {
            match symbol {
                Symbol::Terminal(term) => {
                    result.insert(term.clone());
                    break;
                }
                Symbol::NonTerminal(non_term) => {
                    if let Some(first) = self.first_sets.get(symbol) {
                        result.extend(first.iter().cloned());
                        if !first.contains(&Terminal("ε".to_string())) {
                            break;
                        }
                    }
                }
            }
        }
        
        result
    }
    
    fn compute_follow_sets(&mut self) {
        // 计算FOLLOW集合
        // 简化实现
    }
    
    fn build_parsing_table(&mut self) -> Result<(), String> {
        // 构建LL(1)分析表
        for production in &self.grammar.productions {
            let first = self.first_of_sequence(&production.right);
            
            for terminal in first {
                if terminal.0 != "ε" {
                    let key = (production.left.clone(), terminal);
                    if self.parsing_table.contains_key(&key) {
                        return Err("Grammar is not LL(1)".to_string());
                    }
                    self.parsing_table.insert(key, production.clone());
                }
            }
        }
        
        Ok(())
    }
    
    pub fn parse(&self, input: &str) -> Result<(), String> {
        let mut stack = vec![Symbol::NonTerminal(self.grammar.start_symbol.clone())];
        let mut input_tokens: Vec<Terminal> = input.chars()
            .map(|c| Terminal(c.to_string()))
            .collect();
        input_tokens.push(Terminal("$".to_string()));
        
        let mut input_pos = 0;
        
        while !stack.is_empty() {
            let top = stack.pop().unwrap();
            
            match top {
                Symbol::Terminal(term) => {
                    if input_pos >= input_tokens.len() || 
                       input_tokens[input_pos] != term {
                        return Err("Input mismatch".to_string());
                    }
                    input_pos += 1;
                }
                Symbol::NonTerminal(non_term) => {
                    let lookahead = &input_tokens[input_pos];
                    if let Some(production) = self.parsing_table.get(&(non_term, lookahead.clone())) {
                        // 将产生式右部逆序压栈
                        for symbol in production.right.iter().rev() {
                            stack.push(symbol.clone());
                        }
                    } else {
                        return Err("No valid production".to_string());
                    }
                }
            }
        }
        
        Ok(())
    }
}
```

## 3.0 LR分析器

### 3.1 LR(0)分析

**定义 3.1.1 (LR(0)项目)**
LR(0)项目是形如 $A \to \alpha \cdot \beta$ 的产生式，其中 $\cdot$ 表示分析位置。

**定义 3.1.2 (项目集闭包)**
项目集 $I$ 的闭包定义为：
$$\text{CLOSURE}(I) = I \cup \{B \to \cdot \gamma \mid A \to \alpha \cdot B\beta \in \text{CLOSURE}(I), B \to \gamma \in P\}$$

**定义 3.1.3 (GOTO函数)**
GOTO函数定义为：
$$\text{GOTO}(I, X) = \text{CLOSURE}(\{A \to \alpha X \cdot \beta \mid A \to \alpha \cdot X\beta \in I\})$$

```rust
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct LR0Item {
    production: Production,
    dot_position: usize,
}

impl LR0Item {
    pub fn new(production: Production) -> Self {
        Self {
            production,
            dot_position: 0,
        }
    }
    
    pub fn next_symbol(&self) -> Option<&Symbol> {
        self.production.right.get(self.dot_position)
    }
    
    pub fn advance(&self) -> Option<LR0Item> {
        if self.dot_position < self.production.right.len() {
            let mut new_item = self.clone();
            new_item.dot_position += 1;
            Some(new_item)
        } else {
            None
        }
    }
}

#[derive(Debug, Clone)]
pub struct LR0Parser {
    grammar: ContextFreeGrammar,
    states: Vec<HashSet<LR0Item>>,
    action_table: HashMap<(usize, Terminal), Action>,
    goto_table: HashMap<(usize, NonTerminal), usize>,
}

#[derive(Debug, Clone)]
pub enum Action {
    Shift(usize),
    Reduce(Production),
    Accept,
    Error,
}

impl LR0Parser {
    pub fn new(grammar: ContextFreeGrammar) -> Self {
        let mut parser = Self {
            grammar,
            states: Vec::new(),
            action_table: HashMap::new(),
            goto_table: HashMap::new(),
        };
        
        parser.build_automaton();
        parser.build_tables();
        
        parser
    }
    
    fn build_automaton(&mut self) {
        // 构建LR(0)自动机
        let initial_item = LR0Item::new(Production {
            left: NonTerminal("S'".to_string()),
            right: vec![Symbol::NonTerminal(self.grammar.start_symbol.clone())],
        });
        
        let initial_state = self.closure(&[initial_item]);
        self.states.push(initial_state);
        
        let mut unprocessed = vec![0];
        
        while let Some(state_id) = unprocessed.pop() {
            let state = &self.states[state_id];
            
            // 计算所有可能的转移
            let mut transitions = HashMap::new();
            for item in state {
                if let Some(symbol) = item.next_symbol() {
                    if let Some(next_item) = item.advance() {
                        transitions.entry(symbol.clone())
                            .or_insert_with(Vec::new)
                            .push(next_item);
                    }
                }
            }
            
            // 创建新状态
            for (symbol, items) in transitions {
                let new_state = self.closure(&items);
                
                if let Some(existing_state_id) = self.find_state(&new_state) {
                    // 状态已存在
                    match symbol {
                        Symbol::Terminal(term) => {
                            self.action_table.insert((state_id, term), Action::Shift(existing_state_id));
                        }
                        Symbol::NonTerminal(non_term) => {
                            self.goto_table.insert((state_id, non_term), existing_state_id);
                        }
                    }
                } else {
                    // 新状态
                    let new_state_id = self.states.len();
                    self.states.push(new_state);
                    unprocessed.push(new_state_id);
                    
                    match symbol {
                        Symbol::Terminal(term) => {
                            self.action_table.insert((state_id, term), Action::Shift(new_state_id));
                        }
                        Symbol::NonTerminal(non_term) => {
                            self.goto_table.insert((state_id, non_term), new_state_id);
                        }
                    }
                }
            }
        }
    }
    
    fn closure(&self, items: &[LR0Item]) -> HashSet<LR0Item> {
        let mut closure = items.iter().cloned().collect::<HashSet<_>>();
        let mut changed = true;
        
        while changed {
            changed = false;
            let mut new_items = Vec::new();
            
            for item in &closure {
                if let Some(Symbol::NonTerminal(non_term)) = item.next_symbol() {
                    for production in &self.grammar.productions {
                        if production.left == *non_term {
                            let new_item = LR0Item::new(production.clone());
                            if !closure.contains(&new_item) {
                                new_items.push(new_item);
                                changed = true;
                            }
                        }
                    }
                }
            }
            
            closure.extend(new_items);
        }
        
        closure
    }
    
    fn find_state(&self, state: &HashSet<LR0Item>) -> Option<usize> {
        for (i, existing_state) in self.states.iter().enumerate() {
            if existing_state == state {
                return Some(i);
            }
        }
        None
    }
    
    fn build_tables(&mut self) {
        // 构建ACTION和GOTO表
        for (state_id, state) in self.states.iter().enumerate() {
            for item in state {
                if item.next_symbol().is_none() {
                    // 规约项目
                    if item.production.left.0 == "S'" {
                        self.action_table.insert((state_id, Terminal("$".to_string())), Action::Accept);
                    } else {
                        for terminal in &self.grammar.terminals {
                            self.action_table.insert((state_id, terminal.clone()), Action::Reduce(item.production.clone()));
                        }
                    }
                }
            }
        }
    }
    
    pub fn parse(&self, input: &str) -> Result<(), String> {
        let mut stack = vec![0]; // 状态栈
        let mut input_tokens: Vec<Terminal> = input.chars()
            .map(|c| Terminal(c.to_string()))
            .collect();
        input_tokens.push(Terminal("$".to_string()));
        
        let mut input_pos = 0;
        
        loop {
            let current_state = *stack.last().unwrap();
            let lookahead = &input_tokens[input_pos];
            
            if let Some(action) = self.action_table.get(&(current_state, lookahead.clone())) {
                match action {
                    Action::Shift(next_state) => {
                        stack.push(*next_state);
                        input_pos += 1;
                    }
                    Action::Reduce(production) => {
                        // 弹出|β|个状态
                        for _ in 0..production.right.len() {
                            stack.pop();
                        }
                        
                        let current_state = *stack.last().unwrap();
                        if let Some(next_state) = self.goto_table.get(&(current_state, production.left.clone())) {
                            stack.push(*next_state);
                        } else {
                            return Err("GOTO table error".to_string());
                        }
                    }
                    Action::Accept => {
                        return Ok(());
                    }
                    Action::Error => {
                        return Err("Parse error".to_string());
                    }
                }
            } else {
                return Err("No action found".to_string());
            }
        }
    }
}
```

### 3.2 SLR(1)分析

**定义 3.2.1 (SLR(1)条件)**
对于规约项目 $A \to \alpha \cdot$，只有当输入符号 $a \in \text{FOLLOW}(A)$ 时才进行规约。

```rust
#[derive(Debug, Clone)]
pub struct SLR1Parser {
    lr0_parser: LR0Parser,
    follow_sets: HashMap<NonTerminal, HashSet<Terminal>>,
}

impl SLR1Parser {
    pub fn new(grammar: ContextFreeGrammar) -> Result<Self, String> {
        let lr0_parser = LR0Parser::new(grammar.clone());
        let mut parser = Self {
            lr0_parser,
            follow_sets: HashMap::new(),
        };
        
        parser.compute_follow_sets();
        parser.resolve_conflicts()?;
        
        Ok(parser)
    }
    
    fn compute_follow_sets(&mut self) {
        // 计算FOLLOW集合
        // 简化实现
    }
    
    fn resolve_conflicts(&mut self) -> Result<(), String> {
        // 使用FOLLOW集合解决冲突
        // 简化实现
        Ok(())
    }
    
    pub fn parse(&self, input: &str) -> Result<(), String> {
        self.lr0_parser.parse(input)
    }
}
```

## 4.0 语法树构建

**定义 4.1.1 (抽象语法树)**
抽象语法树是源代码语法结构的树形表示。

```rust
#[derive(Debug, Clone)]
pub struct ASTNode {
    node_type: String,
    value: Option<String>,
    children: Vec<ASTNode>,
}

impl ASTNode {
    pub fn new(node_type: String) -> Self {
        Self {
            node_type,
            value: None,
            children: Vec::new(),
        }
    }
    
    pub fn with_value(node_type: String, value: String) -> Self {
        Self {
            node_type,
            value: Some(value),
            children: Vec::new(),
        }
    }
    
    pub fn add_child(&mut self, child: ASTNode) {
        self.children.push(child);
    }
    
    pub fn print(&self, indent: usize) {
        let spaces = "  ".repeat(indent);
        if let Some(value) = &self.value {
            println!("{}{}: {}", spaces, self.node_type, value);
        } else {
            println!("{}{}", spaces, self.node_type);
        }
        
        for child in &self.children {
            child.print(indent + 1);
        }
    }
}

#[derive(Debug, Clone)]
pub struct ASTBuilder {
    stack: Vec<ASTNode>,
}

impl ASTBuilder {
    pub fn new() -> Self {
        Self { stack: Vec::new() }
    }
    
    pub fn push_terminal(&mut self, value: String) {
        let node = ASTNode::with_value("Terminal".to_string(), value);
        self.stack.push(node);
    }
    
    pub fn reduce(&mut self, production: &Production) {
        let mut children = Vec::new();
        
        // 弹出产生式右部的节点
        for _ in 0..production.right.len() {
            if let Some(child) = self.stack.pop() {
                children.insert(0, child);
            }
        }
        
        // 创建新的非终结符节点
        let mut node = ASTNode::new(production.left.0.clone());
        for child in children {
            node.add_child(child);
        }
        
        self.stack.push(node);
    }
    
    pub fn get_tree(&self) -> Option<&ASTNode> {
        self.stack.last()
    }
}
```

## 5.0 错误恢复

**定义 5.1.1 (错误恢复策略)**
错误恢复策略包括：
1. 紧急模式恢复
2. 短语级恢复
3. 错误产生式
4. 全局纠正

```rust
#[derive(Debug, Clone)]
pub struct ErrorRecovery {
    panic_mode: bool,
    error_tokens: HashSet<Terminal>,
}

impl ErrorRecovery {
    pub fn new() -> Self {
        Self {
            panic_mode: false,
            error_tokens: HashSet::new(),
        }
    }
    
    pub fn panic_mode_recovery(&mut self, parser: &mut LR0Parser, input: &str) -> Result<(), String> {
        // 紧急模式恢复：跳过输入直到遇到同步标记
        self.panic_mode = true;
        
        // 简化实现
        Ok(())
    }
    
    pub fn phrase_level_recovery(&mut self, parser: &mut LR0Parser, input: &str) -> Result<(), String> {
        // 短语级恢复：在局部范围内进行错误修复
        // 简化实现
        Ok(())
    }
}
```

## 6.0 语法优化

**定义 6.1.1 (语法优化)**
语法优化包括：
1. 消除左递归
2. 提取左公因子
3. 消除无用符号
4. 消除ε产生式

```rust
#[derive(Debug, Clone)]
pub struct GrammarOptimizer {
}

impl GrammarOptimizer {
    pub fn eliminate_left_recursion(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 消除左递归
        // 简化实现：返回原文法
        grammar.clone()
    }
    
    pub fn extract_left_factors(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 提取左公因子
        // 简化实现：返回原文法
        grammar.clone()
    }
    
    pub fn remove_useless_symbols(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 消除无用符号
        // 简化实现：返回原文法
        grammar.clone()
    }
    
    pub fn remove_epsilon_productions(grammar: &ContextFreeGrammar) -> ContextFreeGrammar {
        // 消除ε产生式
        // 简化实现：返回原文法
        grammar.clone()
    }
}
```

---

## 总结

语法分析理论为语言处理提供了形式化基础，通过CFG、LL分析、LR分析等核心概念，我们可以：

1. **语言定义**：使用文法定义语言结构
2. **语法分析**：构建高效的语法分析器
3. **错误处理**：实现健壮的错误恢复机制
4. **代码生成**：基于语法树生成目标代码

这种形式化方法确保了语言处理的正确性和效率。 