#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥å…·é“¾é›†æˆæµ‹è¯•
Toolchain Integration Test

éªŒè¯FormalUnifiedå·¥å…·é“¾ä¸­å„ç»„ä»¶çš„ååŒå·¥ä½œèƒ½åŠ›
"""

import asyncio
import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import subprocess
import sys

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ToolchainIntegrationTest:
    """å·¥å…·é“¾é›†æˆæµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = time.time()
        self.base_path = Path(__file__).parent
        
    async def run_integration_tests(self):
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        logger.info("ğŸ”§ å¼€å§‹å·¥å…·é“¾é›†æˆæµ‹è¯•")
        
        # 1. æµ‹è¯•ç†è®ºåˆ°å®è·µæ˜ å°„å·¥å…·
        await self._test_theory_mapper()
        
        # 2. æµ‹è¯•è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆå™¨
        await self._test_code_generator()
        
        # 3. æµ‹è¯•è·¨ç†è®ºéªŒè¯å¼•æ“
        await self._test_verification_engine()
        
        # 4. æµ‹è¯•ç»¼åˆæ¼”ç¤ºè„šæœ¬
        await self._test_comprehensive_demo()
        
        # 5. æµ‹è¯•å·¥å…·é—´é›†æˆ
        await self._test_tool_integration()
        
        # 6. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self._generate_test_report()
        
        logger.info("âœ… å·¥å…·é“¾é›†æˆæµ‹è¯•å®Œæˆ")
    
    async def _test_theory_mapper(self):
        """æµ‹è¯•ç†è®ºåˆ°å®è·µæ˜ å°„å·¥å…·"""
        logger.info("ğŸ“‹ æµ‹è¯•ç†è®ºåˆ°å®è·µæ˜ å°„å·¥å…·")
        
        try:
            # æµ‹è¯•describeåŠŸèƒ½
            result = subprocess.run([
                sys.executable, str(self.base_path / "theory_to_practice_mapper.py"),
                "--describe", "--config", str(self.base_path / "config.yaml")
            ], capture_output=True, text=True, check=True)
            
            describe_data = json.loads(result.stdout)
            if describe_data.get("status") == "ok":
                self.test_results["theory_mapper"] = {
                    "status": "PASS",
                    "supported_languages": describe_data["data"]["supported_languages"],
                    "supported_patterns": describe_data["data"]["supported_patterns"],
                    "coverage": describe_data["data"]["coverage"]
                }
                logger.info("âœ… ç†è®ºæ˜ å°„å·¥å…·æµ‹è¯•é€šè¿‡")
            else:
                self.test_results["theory_mapper"] = {"status": "FAIL", "error": "describeè¿”å›å¼‚å¸¸"}
                
        except Exception as e:
            self.test_results["theory_mapper"] = {"status": "FAIL", "error": str(e)}
            logger.error(f"âŒ ç†è®ºæ˜ å°„å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
    
    async def _test_code_generator(self):
        """æµ‹è¯•è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆå™¨"""
        logger.info("âš™ï¸ æµ‹è¯•è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆå™¨")
        
        try:
            # æµ‹è¯•å¹²è·‘æ¨¡å¼
            result = subprocess.run([
                sys.executable, str(self.base_path / "AutomatedCodeGenerator" / "automated_code_generator.py"),
                "--language", "python", "--pattern", "state_machine", "--dry-run",
                "--config", str(self.base_path / "config.yaml")
            ], capture_output=True, text=True, check=True)
            
            if "ç”Ÿæˆ" in result.stdout and "æ–‡ä»¶" in result.stdout:
                self.test_results["code_generator"] = {
                    "status": "PASS",
                    "output": result.stdout.strip()
                }
                logger.info("âœ… ä»£ç ç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡")
            else:
                self.test_results["code_generator"] = {"status": "FAIL", "error": "è¾“å‡ºæ ¼å¼å¼‚å¸¸"}
                
        except Exception as e:
            self.test_results["code_generator"] = {"status": "FAIL", "error": str(e)}
            logger.error(f"âŒ ä»£ç ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
    
    async def _test_verification_engine(self):
        """æµ‹è¯•è·¨ç†è®ºéªŒè¯å¼•æ“"""
        logger.info("ğŸ” æµ‹è¯•è·¨ç†è®ºéªŒè¯å¼•æ“")
        
        try:
            # è¿è¡ŒéªŒè¯å¼•æ“
            result = subprocess.run([
                sys.executable, str(self.base_path / "CrossTheoryVerificationEngine.py")
            ], capture_output=True, text=True, check=True)
            
            if "éªŒè¯ç»“æœå·²å¯¼å‡º" in result.stdout:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                output_dir = Path("verification_output")
                if output_dir.exists() and (output_dir / "verification_report.json").exists():
                    self.test_results["verification_engine"] = {
                        "status": "PASS",
                        "output_files": [f.name for f in output_dir.iterdir() if f.is_file()]
                    }
                    logger.info("âœ… éªŒè¯å¼•æ“æµ‹è¯•é€šè¿‡")
                else:
                    self.test_results["verification_engine"] = {"status": "FAIL", "error": "è¾“å‡ºæ–‡ä»¶ç¼ºå¤±"}
            else:
                self.test_results["verification_engine"] = {"status": "FAIL", "error": "éªŒè¯è¿‡ç¨‹å¼‚å¸¸"}
                
        except Exception as e:
            self.test_results["verification_engine"] = {"status": "FAIL", "error": str(e)}
            logger.error(f"âŒ éªŒè¯å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
    
    async def _test_comprehensive_demo(self):
        """æµ‹è¯•ç»¼åˆæ¼”ç¤ºè„šæœ¬"""
        logger.info("ğŸ­ æµ‹è¯•ç»¼åˆæ¼”ç¤ºè„šæœ¬")
        
        try:
            # è¿è¡Œç»¼åˆæ¼”ç¤º
            result = subprocess.run([
                sys.executable, str(self.base_path / "comprehensive_demo.py")
            ], capture_output=True, text=True, check=True)
            
            if "ç»¼åˆæ¼”ç¤ºå®Œæˆ" in result.stdout:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                demo_files = ["demo_report.json", "demo_report.md"]
                existing_files = [f for f in demo_files if Path(f).exists()]
                
                self.test_results["comprehensive_demo"] = {
                    "status": "PASS",
                    "output_files": existing_files
                }
                logger.info("âœ… ç»¼åˆæ¼”ç¤ºæµ‹è¯•é€šè¿‡")
            else:
                self.test_results["comprehensive_demo"] = {"status": "FAIL", "error": "æ¼”ç¤ºè¿‡ç¨‹å¼‚å¸¸"}
                
        except Exception as e:
            self.test_results["comprehensive_demo"] = {"status": "FAIL", "error": str(e)}
            logger.error(f"âŒ ç»¼åˆæ¼”ç¤ºæµ‹è¯•å¤±è´¥: {e}")
    
    async def _test_tool_integration(self):
        """æµ‹è¯•å·¥å…·é—´é›†æˆ"""
        logger.info("ğŸ”— æµ‹è¯•å·¥å…·é—´é›†æˆ")
        
        try:
            # æµ‹è¯•æ˜ å°„å·¥å…·ä¸ä»£ç ç”Ÿæˆå™¨çš„é›†æˆ
            # 1. è·å–æ˜ å°„ä¿¡æ¯
            mapper_result = subprocess.run([
                sys.executable, str(self.base_path / "theory_to_practice_mapper.py"),
                "--pattern", "state_machine", "--language", "rust",
                "--config", str(self.base_path / "config.yaml")
            ], capture_output=True, text=True, check=True)
            
            mapper_data = json.loads(mapper_result.stdout)
            
            if mapper_data.get("status") == "ok":
                # 2. ä½¿ç”¨ç›¸åŒå‚æ•°è¿è¡Œä»£ç ç”Ÿæˆå™¨
                generator_result = subprocess.run([
                    sys.executable, str(self.base_path / "AutomatedCodeGenerator" / "automated_code_generator.py"),
                    "--language", "rust", "--pattern", "state_machine", "--dry-run",
                    "--config", str(self.base_path / "config.yaml")
                ], capture_output=True, text=True, check=True)
                
                if "æ˜ å°„æ¨¡æ¿" in generator_result.stdout and "ç”Ÿæˆ" in generator_result.stdout:
                    self.test_results["tool_integration"] = {
                        "status": "PASS",
                        "mapper_template": mapper_data.get("template_name"),
                        "integration_flow": "æ˜ å°„å·¥å…· â†’ ä»£ç ç”Ÿæˆå™¨"
                    }
                    logger.info("âœ… å·¥å…·é›†æˆæµ‹è¯•é€šè¿‡")
                else:
                    self.test_results["tool_integration"] = {"status": "FAIL", "error": "é›†æˆæµç¨‹å¼‚å¸¸"}
            else:
                self.test_results["tool_integration"] = {"status": "FAIL", "error": "æ˜ å°„å·¥å…·è¿”å›å¼‚å¸¸"}
                
        except Exception as e:
            self.test_results["tool_integration"] = {"status": "FAIL", "error": str(e)}
            logger.error(f"âŒ å·¥å…·é›†æˆæµ‹è¯•å¤±è´¥: {e}")
    
    def _generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š")
        
        # è®¡ç®—æµ‹è¯•æ—¶é—´
        test_duration = time.time() - self.start_time
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() if result.get("status") == "PASS")
        failed_tests = total_tests - passed_tests
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "test_info": {
                "test_duration": f"{test_duration:.2f}ç§’",
                "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "success_rate": f"{(passed_tests/total_tests)*100:.1f}%" if total_tests > 0 else "0%"
            },
            "test_results": self.test_results,
            "summary": {
                "overall_status": "PASS" if failed_tests == 0 else "FAIL",
                "recommendations": self._generate_recommendations()
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path("toolchain_integration_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_report = self._generate_markdown_report(report)
        markdown_file = Path("toolchain_integration_report.md")
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logger.info(f"âœ… é›†æˆæµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}, {markdown_file}")
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        failed_tests = [name for name, result in self.test_results.items() if result.get("status") == "FAIL"]
        
        if failed_tests:
            recommendations.append(f"éœ€è¦ä¿®å¤å¤±è´¥çš„æµ‹è¯•: {', '.join(failed_tests)}")
        
        if "theory_mapper" in self.test_results and self.test_results["theory_mapper"].get("status") == "PASS":
            coverage = self.test_results["theory_mapper"].get("coverage", {})
            if coverage:
                total_combinations = sum(len(langs) for langs in coverage.values())
                recommendations.append(f"æ˜ å°„å·¥å…·æ”¯æŒ {total_combinations} ç§æ¨¡å¼-è¯­è¨€ç»„åˆ")
        
        if "tool_integration" in self.test_results and self.test_results["tool_integration"].get("status") == "PASS":
            recommendations.append("å·¥å…·é“¾é›†æˆè‰¯å¥½ï¼Œå¯ä»¥æ”¯æŒç«¯åˆ°ç«¯çš„ç†è®ºåˆ°ä»£ç ç”Ÿæˆæµç¨‹")
        
        return recommendations
    
    def _generate_markdown_report(self, report: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        md = "# å·¥å…·é“¾é›†æˆæµ‹è¯•æŠ¥å‘Š\n\n"
        
        # æµ‹è¯•ä¿¡æ¯
        md += "## æµ‹è¯•ä¿¡æ¯\n\n"
        md += f"- **æµ‹è¯•æ—¶é—´**: {report['test_info']['test_time']}\n"
        md += f"- **æµ‹è¯•æ—¶é•¿**: {report['test_info']['test_duration']}\n"
        md += f"- **æ€»æµ‹è¯•æ•°**: {report['test_info']['total_tests']}\n"
        md += f"- **é€šè¿‡æµ‹è¯•**: {report['test_info']['passed_tests']}\n"
        md += f"- **å¤±è´¥æµ‹è¯•**: {report['test_info']['failed_tests']}\n"
        md += f"- **æˆåŠŸç‡**: {report['test_info']['success_rate']}\n\n"
        
        # æµ‹è¯•ç»“æœ
        md += "## æµ‹è¯•ç»“æœ\n\n"
        for test_name, result in report['test_results'].items():
            status_icon = "âœ…" if result.get("status") == "PASS" else "âŒ"
            md += f"### {test_name}\n"
            md += f"- **çŠ¶æ€**: {status_icon} {result.get('status')}\n"
            
            if result.get("status") == "PASS":
                for key, value in result.items():
                    if key != "status":
                        md += f"- **{key}**: {value}\n"
            else:
                md += f"- **é”™è¯¯**: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
            md += "\n"
        
        # æ€»ç»“
        md += "## æ€»ç»“\n\n"
        md += f"- **æ€»ä½“çŠ¶æ€**: {report['summary']['overall_status']}\n\n"
        
        if report['summary']['recommendations']:
            md += "### å»ºè®®\n\n"
            for rec in report['summary']['recommendations']:
                md += f"- {rec}\n"
        
        return md

async def main():
    """ä¸»å‡½æ•°"""
    test = ToolchainIntegrationTest()
    await test.run_integration_tests()

if __name__ == "__main__":
    asyncio.run(main()) 